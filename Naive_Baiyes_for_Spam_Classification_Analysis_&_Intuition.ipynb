{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naive Baiyes for Spam Classifier - Analysis & Intuition",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ot83Mv2RhQet",
        "colab_type": "text"
      },
      "source": [
        "## Naive Bayes for Spam Classification\n",
        "\n",
        "In this section we will build a spam classificator using Naive Bayes probabilistic ML technique.\n",
        "\n",
        "**Tip**: Remember, the first thing you will do when you receive some problem is transform it from business problem to ML problem. \n",
        "Example: Filter Spam >>> Take raw emails and pre-process text data. Then train a ML model that classifies the email as either spam or not-spam.\n",
        "\n",
        "In ML we commonly have two types of problems:\n",
        "\n",
        "* **Regressions**: You need to predict a number (time, value, amount etc.) \n",
        "\n",
        "* **Classification:** You need to classify something (Cancer or Not Cancer, Spam or Not Spam etc.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILFjQClMjg3t",
        "colab_type": "text"
      },
      "source": [
        "For e-mail classification we have an additional challenge! We will need to adapt the body of our e-mail (text) to numbers (understandable for our algorithm)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_7mOebotVCj",
        "colab_type": "text"
      },
      "source": [
        "## Naive Bayes Classifier\n",
        "\n",
        "The main good attributes of this model are Simplicity and Speed! Spam classification and Weather forecasting are classic applications.\n",
        "\n",
        "**How it works:** To make a decision the naive bayes classify compares probabilities (the likelihood of some event). Translating to our problem, the algorithm will calculate the probability to be or not to be spam. In addition, we will have a chart with two probabilities Spam (x-axis) or Not Spam (y-axis). The 50% / 50% probability will create a straight line called **Decision Boundary**.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8H38S1ivhTr",
        "colab_type": "text"
      },
      "source": [
        "## A little review about probability\n",
        "\n",
        "**1. Basic Probability**\n",
        "\n",
        "Normally in probability problems we will have a division between a small group by a large group. Example: What is the probability to be hit by a ligthning strike? The equation is the amount of people hit by lightning strikes / total amount of lightning strikes (240.000 / 350 MM) ~ 0.07%.\n",
        "\n",
        "In our context, What is the probability of an email being spam? Nr Spam Emails Sent / Total Nr Emails Sent >> 148bn / 269bn = 55%!!\n",
        "\n",
        "\n",
        "**2. Joint Proability**\n",
        "\n",
        "If you flip coin twice, what is the proability to get heads 2x? This is the join probability! when you have additional recurrence. The answer for our problem is 1 / 4 ~ 25%, because we have 2x 50% of chances (50% / 2). Likewise, If you establish a confusion matrix, you will see that heads / heads is only one change in four. Matematically, multiply the probability of getting heads by itself! p(A) x p(B) \n",
        "\n",
        "**Important**: Each time you toss a dice or flip a coin you will have the same probability! Imagine the following situation; you fliped a coin twice and both times you got head. What is the probability to get head again? 50%! The probability are independent by itself!\n",
        "\n",
        "**3. Conditional Probability**\n",
        "\n",
        "This is the hard topic in the probability, here we will have dependency of something to calculate the probability of another event. Given our spam email problem, a spam email is composed by a certain pattern of words and features. But, given the word 'discount' in an email, is this email a spam or not? Measures the probability of some event occur given a previous event has occured. \n",
        "\n",
        "For example, the weather is cloudy, what is the probability of raining today? Given that the day is cloudy, what is the probability of raining?\n",
        "\n",
        "\n",
        "Mathematically:\n",
        "\n",
        "p(Rain / Cloudy) = p(Rain and Cloudy) / p(Cloudy)\n",
        "\n",
        "This sounds fundamental of machine learning right? learn something to aswer another thing. Knowing the move budget we can calculate the revenue, Knowing the number of rooms we can calculate the expected price.\n",
        "\n",
        "The problem here is to calculate the upper probability, when we have dependent actions (independent like toss a dice is easy). To calculate his probability for dependent problems we will use the Bayes Theorem.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpkxuXWW3cHW",
        "colab_type": "text"
      },
      "source": [
        "## Bayes Theorem\n",
        "\n",
        "Given the difficult of our conditional probability, we can reshuffle our equation for an easier version. So, let's change the question for our cloud x raining problem.\n",
        "\n",
        "Given that is raining what is the probability of being cloudy? Mathematically would be: p(Rain / Cloudy) = p(Cloudy / Rain) p(Rain) / p(Cloudy).\n",
        "\n",
        "Let's get back to our Email Spam problem:\n",
        "\n",
        "* p(Spam / Viagra) = p(Viagra / Spam) p(Spam) / p(Viagra)\n",
        "* p(Spam / Viagra) = (65/370.000 >> Check our dataset all emails with viagra and in the spam / all spams) * 0.55% / (75/700.000 >> Google the basic prob) \n",
        "\n",
        "In an email we can calculate for every single word the probability of being in an ordinary spam email. We can also use NPL to make our job easier, because some words are more frequent in spam emails.\n",
        "\n",
        "Let's give another example: given that email has the word 'free' and 'viagra'?\n",
        "We will the joint probabilities of conditional probabilities like we have seen previously, because the events are independent! \n",
        "\n",
        "**The Naive from Naive Bayes assumes independency of each word, that's the trick in our algorithm!**\n",
        "\n",
        "So, image an email with the following body: \"Hello friend, Want free viagra?\" we will calculate the joint probabilities from condition probabilities in each word of being spam and not being spam to plot in our graph!\n",
        "\n",
        "p(Spam / Hello) * p(Spam / Want) * p(Spam / Free) * p(Spam / Viagra)\n",
        "\n",
        "p(Normal / Hello) * p(Normal / Want) * p(Normal / Free) * p(Normal / Viagra)\n",
        "\n",
        "We will use the **bag of words** technique: each word is looked isoletedly, removing dependency of words like (New York or Bad Idea). \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVgAzBT88Pre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import libraries and creating constants\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "\n",
        "from os import walk\n",
        "from os.path import join\n",
        "from sklearn.model_selection import train_test_split\n",
        "from bs4 import BeautifulSoup ## Library that is used for Webscrapping and RPA. It is helpful for treating HTML\n",
        "\n",
        "# Text Pre-processing Package - NLTK \n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer # Cambridge University - English Language\n",
        "from nltk.stem import SnowballStemmer # For other languages \n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Constants for relative file path\n",
        "# For Google Colaboratory you need to upload this files on the cloud (Google Drive)\n",
        "# If you are using cloud storage (Google Drive) you don't need to use 'r' as a file path\n",
        "\n",
        "RELATIVE_PATH_EXAMPLE = '/content/drive/My Drive/SpamData/01_Processing/practice_email.txt'  \n",
        "SPAM_1_PATH = '/content/drive/My Drive/SpamData/01_Processing/spam_assassin_corpus/spam_1'\n",
        "SPAM_2_PATH = '/content/drive/My Drive/SpamData/01_Processing/spam_assassin_corpus/spam_2'\n",
        "EASY_NONSPAM_1_PATH = '/content/drive/My Drive/SpamData/01_Processing/spam_assassin_corpus/easy_ham_1'\n",
        "EASY_NONSPAM_2_PATH = '/content/drive/My Drive/SpamData/01_Processing/spam_assassin_corpus/easy_ham_2'\n",
        "\n",
        "SPAM_CATEGORY = 1\n",
        "HAM_CATEGORY = 0\n",
        "VOCAB_SIZE = 2500\n",
        "\n",
        "DATA_JSON_FILE = '/content/drive/My Drive/SpamData/01_Processing/email-text-data.json'\n",
        "WORD_ID_FILE = '/content/drive/My Drive/SpamData/01_Processing/word-by-id.csv'\n",
        "\n",
        "TRAINING_DATA_FILE ='/content/drive/My Drive/SpamData/02_Training/train-data.txt'\n",
        "TEST_DATA_FILE = '/content/drive/My Drive/SpamData/02_Training/test-data.txt'\n",
        "\n",
        "WHALE_FILE = r'SpamData\\01_Processing\\wordcloud_resources\\whale-icon.png'\n",
        "THUMBS_UP_FILE= r'SpamData\\01_Processing\\wordcloud_resources\\thumbs-up.png'\n",
        "THUMBS_DOWN_FILE= r'SpamData\\01_Processing\\wordcloud_resources\\thumbs-down.png'\n"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kCDL4aEARah",
        "colab_type": "text"
      },
      "source": [
        "## **Step 1: Reading our data from files**\n",
        "\n",
        "Our data is structured in two folders. One contains files with spam e-mails, and the other contains files from regular emails (as known as ham). Thus, we need to create a structure to opean each file, read and save into a string or list.\n",
        "\n",
        "Data preparation steps: \n",
        "\n",
        "  1. Read all e-mails and extract the e-mail body\n",
        "  2. Create a pandas DataFrame with classification Spam / Not Spam for all e-mails\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p__meTVx5SBX",
        "colab_type": "text"
      },
      "source": [
        "First let's start with some examples:\n",
        "\n",
        "* Example 1: Reading one e-mail as a sample. (Raw data)\n",
        "* Example 2: Extracting the e-mail body. (This will be the data for our model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Awi0PTj-5sy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "df03041e-04fb-466b-84ba-0b3c9b5de779"
      },
      "source": [
        "# Here is an example from an e-mail that will be part of our analysis\n",
        "stream = open(RELATIVE_PATH_EXAMPLE, encoding='latin-1')\n",
        "message= stream.read()\n",
        "stream.close()\n",
        "\n",
        "print(message)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From exmh-workers-admin@redhat.com  Thu Aug 22 12:36:23 2002\n",
            "Return-Path: <exmh-workers-admin@spamassassin.taint.org>\n",
            "Delivered-To: zzzz@localhost.netnoteinc.com\n",
            "Received: from localhost (localhost [127.0.0.1])\n",
            "\tby phobos.labs.netnoteinc.com (Postfix) with ESMTP id D03E543C36\n",
            "\tfor <zzzz@localhost>; Thu, 22 Aug 2002 07:36:16 -0400 (EDT)\n",
            "Received: from phobos [127.0.0.1]\n",
            "\tby localhost with IMAP (fetchmail-5.9.0)\n",
            "\tfor zzzz@localhost (single-drop); Thu, 22 Aug 2002 12:36:16 +0100 (IST)\n",
            "Received: from listman.spamassassin.taint.org (listman.spamassassin.taint.org [66.187.233.211]) by\n",
            "    dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g7MBYrZ04811 for\n",
            "    <zzzz-exmh@spamassassin.taint.org>; Thu, 22 Aug 2002 12:34:53 +0100\n",
            "Received: from listman.spamassassin.taint.org (localhost.localdomain [127.0.0.1]) by\n",
            "    listman.redhat.com (Postfix) with ESMTP id 8386540858; Thu, 22 Aug 2002\n",
            "    07:35:02 -0400 (EDT)\n",
            "Delivered-To: exmh-workers@listman.spamassassin.taint.org\n",
            "Received: from int-mx1.corp.spamassassin.taint.org (int-mx1.corp.spamassassin.taint.org\n",
            "    [172.16.52.254]) by listman.redhat.com (Postfix) with ESMTP id 10CF8406D7\n",
            "    for <exmh-workers@listman.redhat.com>; Thu, 22 Aug 2002 07:34:10 -0400\n",
            "    (EDT)\n",
            "Received: (from mail@localhost) by int-mx1.corp.spamassassin.taint.org (8.11.6/8.11.6)\n",
            "    id g7MBY7g11259 for exmh-workers@listman.redhat.com; Thu, 22 Aug 2002\n",
            "    07:34:07 -0400\n",
            "Received: from mx1.spamassassin.taint.org (mx1.spamassassin.taint.org [172.16.48.31]) by\n",
            "    int-mx1.corp.redhat.com (8.11.6/8.11.6) with SMTP id g7MBY7Y11255 for\n",
            "    <exmh-workers@redhat.com>; Thu, 22 Aug 2002 07:34:07 -0400\n",
            "Received: from ratree.psu.ac.th ([202.28.97.6]) by mx1.spamassassin.taint.org\n",
            "    (8.11.6/8.11.6) with SMTP id g7MBIhl25223 for <exmh-workers@redhat.com>;\n",
            "    Thu, 22 Aug 2002 07:18:55 -0400\n",
            "Received: from delta.cs.mu.OZ.AU (delta.coe.psu.ac.th [172.30.0.98]) by\n",
            "    ratree.psu.ac.th (8.11.6/8.11.6) with ESMTP id g7MBWel29762;\n",
            "    Thu, 22 Aug 2002 18:32:40 +0700 (ICT)\n",
            "Received: from munnari.OZ.AU (localhost [127.0.0.1]) by delta.cs.mu.OZ.AU\n",
            "    (8.11.6/8.11.6) with ESMTP id g7MBQPW13260; Thu, 22 Aug 2002 18:26:25\n",
            "    +0700 (ICT)\n",
            "From: Robert Elz <kre@munnari.OZ.AU>\n",
            "To: Chris Garrigues <cwg-dated-1030377287.06fa6d@DeepEddy.Com>\n",
            "Cc: exmh-workers@spamassassin.taint.org\n",
            "Subject: Re: New Sequences Window\n",
            "In-Reply-To: <1029945287.4797.TMDA@deepeddy.vircio.com>\n",
            "References: <1029945287.4797.TMDA@deepeddy.vircio.com>\n",
            "    <1029882468.3116.TMDA@deepeddy.vircio.com> <9627.1029933001@munnari.OZ.AU>\n",
            "    <1029943066.26919.TMDA@deepeddy.vircio.com>\n",
            "    <1029944441.398.TMDA@deepeddy.vircio.com>\n",
            "MIME-Version: 1.0\n",
            "Content-Type: text/plain; charset=us-ascii\n",
            "Message-Id: <13258.1030015585@munnari.OZ.AU>\n",
            "X-Loop: exmh-workers@spamassassin.taint.org\n",
            "Sender: exmh-workers-admin@spamassassin.taint.org\n",
            "Errors-To: exmh-workers-admin@spamassassin.taint.org\n",
            "X-Beenthere: exmh-workers@spamassassin.taint.org\n",
            "X-Mailman-Version: 2.0.1\n",
            "Precedence: bulk\n",
            "List-Help: <mailto:exmh-workers-request@spamassassin.taint.org?subject=help>\n",
            "List-Post: <mailto:exmh-workers@spamassassin.taint.org>\n",
            "List-Subscribe: <https://listman.spamassassin.taint.org/mailman/listinfo/exmh-workers>,\n",
            "    <mailto:exmh-workers-request@redhat.com?subject=subscribe>\n",
            "List-Id: Discussion list for EXMH developers <exmh-workers.spamassassin.taint.org>\n",
            "List-Unsubscribe: <https://listman.spamassassin.taint.org/mailman/listinfo/exmh-workers>,\n",
            "    <mailto:exmh-workers-request@redhat.com?subject=unsubscribe>\n",
            "List-Archive: <https://listman.spamassassin.taint.org/mailman/private/exmh-workers/>\n",
            "Date: Thu, 22 Aug 2002 18:26:25 +0700\n",
            "\n",
            "\n",
            "Dear Mr Still\n",
            "\n",
            "Good tidings to you and all your staff for the festive season ahead (Christmas).\n",
            "Now to the crux of the matter-in-hand: I am a fully qualified Santa Claus and am wondering whether you might consider me to run my own \"Santa's Grotto\" in your store.\n",
            "But WAIT! You're probably thinking: \"What makes him so special?\"\n",
            "Well, first of all, I have made several changes to the characterisation of Father Christmas. Rather than greeting the children with shouts of \"Ho, ho, ho!\" I prefer to whisper the phrase \"Dependence is not unfathomable in this cruel world we live in\". In addition, my gifts are ALL hand-made, ranging from felt hoops to vanilla-pod holders.\n",
            "You will note also, from the enclosed sketch, that I have radically redesigned Santa's outfit and have renamed my character \"Lord Buckles\". Would you be interested in employing me? I promise NEVER to let you down.\n",
            "I look forward to hearing from you.\n",
            "\n",
            "Best wishes\n",
            "Robin Cooper\n",
            "[Excerpt from the book: The Timewaster Letters by Robin Cooper]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCOG99j95Ohb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "745dbb45-224e-4210-9114-7f9fd676c2ab"
      },
      "source": [
        "# Extracting the email body from raw data\n",
        "stream = open(RELATIVE_PATH_EXAMPLE, encoding='latin-1') # Open buffer for file reading. OBS: UTF-8 encoding by default. You can change if necessary\n",
        "\n",
        "is_body = False\n",
        "lines = []\n",
        "\n",
        "for line in stream: # Loops through the file\n",
        "\n",
        "    if is_body: # If is in the body let's append into our list\n",
        "    \n",
        "        lines.append(line)\n",
        "\n",
        "    elif line == '\\n': # In our email the body starts with a blank space \n",
        "\n",
        "        is_body = True\n",
        "        \n",
        "stream.close() # close the buffer\n",
        "\n",
        "# Transform our list into a simple string by using 'Join'!\n",
        "email_body = '\\n'.join(lines) \n",
        "\n",
        "print(email_body)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Dear Mr Still\n",
            "\n",
            "\n",
            "\n",
            "Good tidings to you and all your staff for the festive season ahead (Christmas).\n",
            "\n",
            "Now to the crux of the matter-in-hand: I am a fully qualified Santa Claus and am wondering whether you might consider me to run my own \"Santa's Grotto\" in your store.\n",
            "\n",
            "But WAIT! You're probably thinking: \"What makes him so special?\"\n",
            "\n",
            "Well, first of all, I have made several changes to the characterisation of Father Christmas. Rather than greeting the children with shouts of \"Ho, ho, ho!\" I prefer to whisper the phrase \"Dependence is not unfathomable in this cruel world we live in\". In addition, my gifts are ALL hand-made, ranging from felt hoops to vanilla-pod holders.\n",
            "\n",
            "You will note also, from the enclosed sketch, that I have radically redesigned Santa's outfit and have renamed my character \"Lord Buckles\". Would you be interested in employing me? I promise NEVER to let you down.\n",
            "\n",
            "I look forward to hearing from you.\n",
            "\n",
            "\n",
            "\n",
            "Best wishes\n",
            "\n",
            "Robin Cooper\n",
            "\n",
            "[Excerpt from the book: The Timewaster Letters by Robin Cooper]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koyxTIXT5qHt",
        "colab_type": "text"
      },
      "source": [
        "### Extra Topic: Generator functions & Yield keyword\n",
        "\n",
        "Before we start pre-processing our e-mails (extract the information from the e-mail body and make adjustements / analysis), let's take a look in another way to process massively multiple files.\n",
        "\n",
        "**Generator functions:** This type of function creates an interator that controls automatically all the work of reading and indexing, lists, function calls, file processing etc. It's like if we have a 'memory effect' controller, which allows us gain performance while processing a massive amount of data without affecting directly our memory.\n",
        "\n",
        "Instead the word **'return' we will use the keyword 'yield'** that returns a lazy iterator, like a pointer in C++ preventing memory errors.\n",
        "\n",
        "This special type of function is commonly used for file processing!\n",
        "\n",
        "Let's learn with an example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93hpWfWU773_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_squares(n):\n",
        "\n",
        "  for my_number in range(n): # elevate the number 'n' times as a sequence\n",
        "\n",
        "    yield my_number ** 2 # we don't have return, instead we have yield that acts like a memory from were we stopped"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQ2u-uvH8MWO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db853b06-c81f-4a43-e5a7-ce1a8201f022"
      },
      "source": [
        "# Generator function call\n",
        "\n",
        "for i in generate_squares(10):\n",
        "    \n",
        "    print(i, end='->')\n",
        "\n",
        "# n = 5 the exit will be: 0->1->4->9->16->\n",
        "# n = 10 the exit will be: 0->1->4->9->16->25->36->49->64->81->"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0->1->4->9->16->25->36->49->64->81->"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGQkYGzv8zHb",
        "colab_type": "text"
      },
      "source": [
        "### Extracing our e-mail body from files\n",
        "\n",
        "Now, We have learnt about generator functions. Let's create a function that extracts all the e-mail body from our text files. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v1ulTwM8Y2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def email_body_generator(path):\n",
        "\n",
        "  # 1. Iterates through the file path\n",
        "  # 'walk' function literally walks through the files one by one returning a tuple of informations about file location\n",
        "  for root, dirnames, filenames in walk(path): \n",
        "\n",
        "    # 2. for each file name\n",
        "    for filename in filenames:\n",
        "\n",
        "      # Joins the root path + file name to create a full file path\n",
        "      filepath = join(root, filename)\n",
        "\n",
        "      stream = open(filepath, mode='r', encoding='latin-1') # Open file buffer for reading ('r'), encoded by latin-1\n",
        "\n",
        "      is_body = False # Controls if is a body\n",
        "      lines = [] # List that will save our entire body\n",
        "\n",
        "      for line in stream:\n",
        "\n",
        "        if is_body:\n",
        "\n",
        "          lines.append(line)\n",
        "\n",
        "        elif line == '\\n': # '\\n indicates that is the end of HTML header\n",
        "\n",
        "          is_body = True\n",
        "\n",
        "      stream.close() # Close Buffer\n",
        "      email_body = '\\n'.join(lines) # Join our lines in a full body object\n",
        "\n",
        "      yield filename, email_body\n",
        "\n"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7V3FhrhJsBS",
        "colab_type": "text"
      },
      "source": [
        "### Create pandas DataFrame with classification\n",
        "\n",
        "Now we will create a Data Frame with a classification \n",
        "\n",
        "\n",
        "assign a classification for our emails by using the following assumption:\n",
        "\n",
        "* 1 > Spam\n",
        "* 0 > Not Spam (Commonly assigned as Ham)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rnKclGYJejd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def df_from_directory(path, classification):\n",
        "\n",
        "  rows = []\n",
        "  row_names = []\n",
        "\n",
        "  for file_name, email_body in email_body_generator(path):\n",
        "\n",
        "    rows.append({'Message': email_body, 'Category': classification})\n",
        "    row_names.append(file_name)\n",
        "\n",
        "  return pd.DataFrame(rows, index=row_names)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rXPiEjINMQm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "244d8d76-ccc0-447e-cd26-a88921c15955"
      },
      "source": [
        "# Build our Spam and Non Spam Dataframes\n",
        "spam_emails = df_from_directory(SPAM_1_PATH, SPAM_CATEGORY)\n",
        "spam_emails = spam_emails.append(df_from_directory(SPAM_2_PATH, SPAM_CATEGORY))\n",
        "\n",
        "ham_emails = df_from_directory(EASY_NONSPAM_1_PATH, HAM_CATEGORY)\n",
        "ham_emails = ham_emails.append(df_from_directory(EASY_NONSPAM_2_PATH, HAM_CATEGORY))\n",
        "\n",
        "# Check the shape from DataFrames\n",
        "print('Spam e-mails shape:', spam_emails.shape)\n",
        "print('Spam e-mails shape:', ham_emails.shape)\n",
        "\n",
        "# Concatenate Spam + Not Spam emails in one unique pandas DataFrame\n",
        "data = pd.concat([spam_emails, ham_emails])\n",
        "print('Full DataFrame shape:', data.shape)\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spam e-mails shape: (1898, 2)\n",
            "Spam e-mails shape: (3902, 2)\n",
            "Full DataFrame shape: (5800, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Message</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>00274.ecb5ce751d8768ef609c171b84ca07a9</th>\n",
              "      <td>&lt;html&gt;\\n\\n&lt;head&gt;\\n\\n&lt;title&gt;Digital Publishing ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00089.7e7baae6ef4a8fb945d7b3fe551329fe</th>\n",
              "      <td>Email marketing works!  There's no way around ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00097.013347cc91e7d0915074dccb0428883f</th>\n",
              "      <td>=================================\\n\\n\\n\\nGuara...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00044.9eece8e53a8982c26558b9eb38230bb8</th>\n",
              "      <td>&lt;html&gt;\\n\\n&lt;body&gt;\\n\\n&lt;p&gt;Do you like Sexy Animal...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00443.cac50573829d4df1111b6ead28212e73</th>\n",
              "      <td>&lt;html&gt;\\n\\n&lt;head&gt;\\n\\n&lt;title&gt;Cell Booster Antenn...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                  Message  Category\n",
              "00274.ecb5ce751d8768ef609c171b84ca07a9  <html>\\n\\n<head>\\n\\n<title>Digital Publishing ...         1\n",
              "00089.7e7baae6ef4a8fb945d7b3fe551329fe  Email marketing works!  There's no way around ...         1\n",
              "00097.013347cc91e7d0915074dccb0428883f  =================================\\n\\n\\n\\nGuara...         1\n",
              "00044.9eece8e53a8982c26558b9eb38230bb8  <html>\\n\\n<body>\\n\\n<p>Do you like Sexy Animal...         1\n",
              "00443.cac50573829d4df1111b6ead28212e73  <html>\\n\\n<head>\\n\\n<title>Cell Booster Antenn...         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NakN5ttoQGPy",
        "colab_type": "text"
      },
      "source": [
        "## **Step 2: Cleaning our data and adding an email tracker in the Dataset**\n",
        "\n",
        "In this step we will extract relevant e-mail bodies and check the quality of our data. In addition, we will set up a new numerical index to our data set. Currently, the file name is our unique id from our dataset, and is not trivial manipulate data with a hashed ID. For this reason a new numerical index will be helpful in order to track e-mails later on!\n",
        "\n",
        "Steps to follow:\n",
        "\n",
        "1. Check 'null', NaN, None, or missing values\n",
        "2. Check for empty emails\n",
        "3. Add document index to track emails in the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvQgJCphPq4_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dd242d79-450a-422a-c113-3952e5f387cc"
      },
      "source": [
        "# 1. Checking Null / None --> Do our emails have null values on their bodies?\n",
        "\n",
        "# .isnull >> returns True/False if some null value is found\n",
        "# .values >> get the values and not the boolean result\n",
        "# .any() >> sum up the previous sentence for all DF. \n",
        "data['Message'].isnull().values.any() \n",
        "\n",
        "# Result: False --> Our DataFrame does not contain any Null/None value! In other words we don't have empty emails\n",
        "\n",
        "# Double check --> must return 0 given 'False' statement\n",
        "data.Message.isnull().sum()\n"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCZ9LUJMRuBE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3eb35764-ab9b-49c8-9500-565235a3d6ed"
      },
      "source": [
        "# 2. Checking empty emails --> Do our emails are blank?\n",
        "\n",
        "# The first () will return True or False, and then the .any() will sum up all records that satisfy the sentence in a single answer\n",
        "(data.Message.str.len() == 0).any()\n",
        "# Result: True --> There are blank e-mails!\n",
        "\n",
        "\n",
        "# Check the amount of empty emails\n",
        "(data.Message.str.len() == 0).sum()\n",
        "# Result: 3 emails\n",
        "\n",
        "# Checking the index from these 3 empty emails\n",
        "data[data.Message.str.len() == 0].index # Return the index from the empty emails\n",
        "# Result: Index(['cmds', 'cmds', 'cmds'], dtype='object') ---> cmds is a system file when you unzip emails. So let's remove!\n",
        "\n",
        "\n",
        "# Drop the empty emails rows and overwrites our Data Frame \n",
        "data.drop(['cmds'], inplace=True) #inplace=True >> Overwrite\n",
        "\n",
        "# Validation: Checking again the sum of empty emails\n",
        "(data.Message.str.len() == 0).sum()\n",
        "# Result: 0 --> OK"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsbzzEajSqxk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "38b98817-9f19-4191-ef0a-8aef211ea0e1"
      },
      "source": [
        "# 3. Add document index to track emails in the Dataset\n",
        "\n",
        "# Create our index with the same length from our Dataset\n",
        "document_ids = range(0, len(data.index))\n",
        "\n",
        "# Apply to our dataset\n",
        "data['Doc_ID'] = document_ids\n",
        "\n",
        "# Redirect our file name as a new column before dropping as a index\n",
        "data['File_Name'] = data.index\n",
        "\n",
        "# Drop the previous index (file name witouth any column name), and resettle a new one (Doc_ID)\n",
        "data.set_index('Doc_ID', inplace=True) # inplace = overwritting\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Message</th>\n",
              "      <th>Category</th>\n",
              "      <th>File_Name</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc_ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;html&gt;\\n\\n&lt;head&gt;\\n\\n&lt;title&gt;Digital Publishing ...</td>\n",
              "      <td>1</td>\n",
              "      <td>00274.ecb5ce751d8768ef609c171b84ca07a9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Email marketing works!  There's no way around ...</td>\n",
              "      <td>1</td>\n",
              "      <td>00089.7e7baae6ef4a8fb945d7b3fe551329fe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>=================================\\n\\n\\n\\nGuara...</td>\n",
              "      <td>1</td>\n",
              "      <td>00097.013347cc91e7d0915074dccb0428883f</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;html&gt;\\n\\n&lt;body&gt;\\n\\n&lt;p&gt;Do you like Sexy Animal...</td>\n",
              "      <td>1</td>\n",
              "      <td>00044.9eece8e53a8982c26558b9eb38230bb8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;html&gt;\\n\\n&lt;head&gt;\\n\\n&lt;title&gt;Cell Booster Antenn...</td>\n",
              "      <td>1</td>\n",
              "      <td>00443.cac50573829d4df1111b6ead28212e73</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Message  ...                               File_Name\n",
              "Doc_ID                                                     ...                                        \n",
              "0       <html>\\n\\n<head>\\n\\n<title>Digital Publishing ...  ...  00274.ecb5ce751d8768ef609c171b84ca07a9\n",
              "1       Email marketing works!  There's no way around ...  ...  00089.7e7baae6ef4a8fb945d7b3fe551329fe\n",
              "2       =================================\\n\\n\\n\\nGuara...  ...  00097.013347cc91e7d0915074dccb0428883f\n",
              "3       <html>\\n\\n<body>\\n\\n<p>Do you like Sexy Animal...  ...  00044.9eece8e53a8982c26558b9eb38230bb8\n",
              "4       <html>\\n\\n<head>\\n\\n<title>Cell Booster Antenn...  ...  00443.cac50573829d4df1111b6ead28212e73\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gGl0SY2WAVK",
        "colab_type": "text"
      },
      "source": [
        "### Extra Topic: Saving our data JSON file with Pandas\n",
        "\n",
        "This is really helpful when you need to interact with other platforms. Specially if your model will run with a Web Application!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61ZqPWbBWLYH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.to_json(DATA_JSON_FILE)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwOQfSnfT4zN",
        "colab_type": "text"
      },
      "source": [
        "## **Step 3: Data Visualisation**\n",
        "\n",
        "Let's visualize our data and get a comprehensive knowledge about!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBgHNj-UYFfm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8e4b8e63-09b0-411a-ae1f-17b8bb8be7b2"
      },
      "source": [
        "# Counts the value given the column 'Category'. This will return an array\n",
        "data.Category.value_counts()\n",
        "\n",
        "# Spam = 1.896\n",
        "# Not Spam = 3.900\n",
        "\n",
        "amount_spam = data.Category.value_counts()[1] \n",
        "amount_not_spam = data.Category.value_counts()[0] \n",
        "\n",
        "print('Amount Spam:', amount_spam)\n",
        "print('Amount Not Spam:', amount_not_spam)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Amount Spam: 1896\n",
            "Amount Not Spam: 3901\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHIeStkYYFj8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "bc98b0bf-7026-42ef-b5f1-7d86282b0752"
      },
      "source": [
        "# Pie / Donut Chart Plotting\n",
        "\n",
        "# chart parameters\n",
        "category_names = ['Spam', 'Legit Mail']\n",
        "sizes = [amount_spam, amount_not_spam]\n",
        "custom_colours = ['#D63447','#DAE1E7']\n",
        "\n",
        "\n",
        "plt.figure(figsize=(2, 2), dpi=227) # 227 density of pixels per inch\n",
        "plt.pie(sizes, \n",
        "        labels=category_names, \n",
        "        textprops={'fontsize': 6}, \n",
        "        startangle=90, autopct='%1.2f%%', \n",
        "        colors=custom_colours\n",
        "        #explode=[0, 0.1] >> this offsert separe our pie!\n",
        "       ) # startangle --> Rotate our start angle for better visualization / autopct --> add automatically % / \n",
        "\n",
        "# Let's draw a Donut chart given our Pie Chart!\n",
        "centre_circle = plt.Circle((0,0), radius= 0.6, fc='white') #xy tuple coordinate / radius / colour\n",
        "plt.gca().add_artist(centre_circle)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 454x454 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7K9W1-wWlJt",
        "colab_type": "text"
      },
      "source": [
        "## **Step 4: NPL - Natural Language Processing**\n",
        "\n",
        "NPL is often used for Google Search, Personal Assistants (Siri, Alexia), Sentiment Analysis, Tweets, Google Ad Words, Autocorrection, Spell check, Translating...\n",
        "\n",
        "NLTK is a python package that will help us with many functions for natural language processing.\n",
        "\n",
        "We will follow the steps below to pre-process our data:\n",
        "\n",
        "1. **Lower Case treatment**: Forcefully converts all string to lower case and prevent user incorrect inputs.\n",
        "2. **Tokenising**: Split words individually\n",
        "3. **Stop Words removal**: Exclude articles, conjunctions etc. (Example: 'the', 'to')\n",
        "4. **Stemming**: Transforms a word to it's stem format (Example: Going / Goes = Go)\n",
        "5. **Punctuation treatment**: Exclude commas, exclamation, periods etc.\n",
        "6. **HTML tags removal**: Given our scenario, some e-mails may contain HTML tags that will cause noise for our data\n",
        "\n",
        "**Notice**: This steps are used for ML purposes. Depending on what is your problem you will need another strategy!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPUtA_bncBEx",
        "colab_type": "text"
      },
      "source": [
        "Let's start with examples from our steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jOfXTzwYF5k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ab5e266d-707e-47a9-bada-357d4894ab59"
      },
      "source": [
        "msg = 'All work And no PlaY makes JacK a DULL BOY'\n",
        "\n",
        "nltk.download('punkt') # Download multiple tokenizer tools in a folder \n",
        "\n",
        "# Transforming to lower case\n",
        "word_tokenize(msg.lower())"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['all', 'work', 'and', 'no', 'play', 'makes', 'jack', 'a', 'dull', 'boy']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAaZLuRgYFx4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1249b72f-9cb3-4594-ec37-c311240f8c6e"
      },
      "source": [
        "# Removing Stop Words >> Conjunctions, Linkings \n",
        "# Example: which, at, on, in, the, what etc... This is good for grammar but it's not useful for ML\n",
        "\n",
        "nltk.download('stopwords') # Download the stop word tools for multiple languages and strategies.\n",
        "\n",
        "# Set data structure: This data structure will be helpful in this type of problem, given it's efficiency on searching!\n",
        "# Set >> It is an ordered, unidexed set of items!\n",
        "\n",
        "# Load english stop words in a set\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Example >> Check the stop word\n",
        "if 'this' in stop_words:\n",
        "    \n",
        "    print('found!')"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "found!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClGmIJn2dop7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d117c4b-d6d4-4055-9a3b-7c68504b070d"
      },
      "source": [
        "# Lowering Cases + Tokenising + Removing stop words\n",
        "\n",
        "msg = 'All work and no Play makes Jack a DULL BOY.'\n",
        "\n",
        "words = word_tokenize(msg.lower()) # tokenising and lowering case\n",
        "\n",
        "stop_words = set(stopwords.words('english')) # load english stop words in a set\n",
        "\n",
        "filtered_words = [] # Saves the list without stop words\n",
        "\n",
        "for word in words: # for each word in our message..\n",
        "    \n",
        "    if word not in stop_words: # Check if the word is not a stop word...\n",
        "        \n",
        "        filtered_words.append(word) # Append the result\n",
        "\n",
        "print(filtered_words)\n"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['work', 'play', 'makes', 'jack', 'dull', 'boy', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Cz5tMrqWkTP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e576511e-a239-41de-f3dd-d8ee95c3e463"
      },
      "source": [
        "# Word Stemming + Removing Punctuations\n",
        "\n",
        "# Stemming >> Transform the word into its natural form. (Goes / Going >> Go)\n",
        "\n",
        "# Porter Stemmer >> Default stemmer algorithm for English Language\n",
        "# SnowballStemmer >> Another version for stemming with good efficiency!\n",
        "\n",
        "# Removing Punctuation >> There is a native function called .isalpha() that returns False if it is a punctuation mark.\n",
        "\n",
        "\n",
        "# Let's apply stemming + punctuations treatment on our previous NPL techniques\n",
        "\n",
        "#stemmer = PorterStemmer() --> By default is english\n",
        "stemmer = SnowballStemmer('english') # English language stemmer\n",
        "\n",
        "msg = 'All work and no play makes Jack a dull boy. To be or Not to Be. \\\n",
        "        Nobody expects the Spanish Inquisition'\n",
        "\n",
        "words = word_tokenize(msg.lower()) # tokenising and lowering case\n",
        "\n",
        "stop_words = set(stopwords.words('english')) # load english stop words in a set\n",
        "\n",
        "filtered_words = [] # Saves the list without stop words\n",
        "\n",
        "for word in words: # for each word in our message..\n",
        "    \n",
        "    if word not in stop_words and word.isalpha(): # Check if the word is not a stop word and remove punctuation...\n",
        "\n",
        "        stemmed_word = stemmer.stem(word)\n",
        "        filtered_words.append(stemmed_word) # Append the result\n",
        "\n",
        "print(filtered_words) # With Stemmer! ['work', 'play', 'make', 'jack', 'dull', 'boy', '.']\n",
        "\n"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['work', 'play', 'make', 'jack', 'dull', 'boy', 'nobodi', 'expect', 'spanish', 'inquisit']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDL0u-skiQrM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "e3007afe-40ae-4d3a-af19-857a04bb9716"
      },
      "source": [
        "data.Message"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Doc_ID\n",
              "0       <html>\\n\\n<head>\\n\\n<title>Digital Publishing ...\n",
              "1       Email marketing works!  There's no way around ...\n",
              "2       =================================\\n\\n\\n\\nGuara...\n",
              "3       <html>\\n\\n<body>\\n\\n<p>Do you like Sexy Animal...\n",
              "4       <html>\\n\\n<head>\\n\\n<title>Cell Booster Antenn...\n",
              "                              ...                        \n",
              "5792    On Fri, Jul 19, 2002 at 03:35:36PM +0100 or so...\n",
              "5793      | Date: Wed, 31 Jul 2002 15:13:23 +0100\\n\\n ...\n",
              "5794    gcc, glibc and binutils, which the lfs site sa...\n",
              "5795    --==_Exmh_-2079003886P\\n\\nContent-Type: text/p...\n",
              "5796    On Sat, Jul 27, 2002 at 03:06:15PM +0100, Step...\n",
              "Name: Message, Length: 5797, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kM0XUHXhewcS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ce572967-6ba5-4bb0-ae0d-d22a22504162"
      },
      "source": [
        "# Removing HTML Tags from email body\n",
        "\n",
        "# We will use the BeautifulSoup html.parser as a controller to remove our HTML tags\n",
        "soup = BeautifulSoup(data.at[2,'Message'], 'html.parser') # Text we would like to pass, Our parser\n",
        "\n",
        "print(soup.prettify()) # Brings the message in a better way\n",
        "\n",
        "# Removing HTML tags by getting only text!\n",
        "soup.get_text()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=================================\n",
            "\n",
            "\n",
            "\n",
            "Guaranteed to increase, lift and firm your\n",
            "\n",
            "breasts in 60 days or your money back!!\n",
            "\n",
            "\n",
            "\n",
            "100% herbal and natural.  Proven formula since \n",
            "\n",
            "1996.  Increase  your bust by 1 to 3 sizes within 30-60 \n",
            "\n",
            "days and be all natural.  \n",
            "\n",
            "\n",
            "\n",
            "Click here:\n",
            "\n",
            "http://202.101.163.34:81/li/wangxd/\n",
            "\n",
            "\n",
            "\n",
            "Absolutely no side effects!\n",
            "\n",
            "Be more self confident!\n",
            "\n",
            "Be more comfortable in bed!\n",
            "\n",
            "No more need for a lift or support bra!\n",
            "\n",
            "\n",
            "\n",
            "100% GUARANTEED AND FROM A NAME YOU KNOW AND \n",
            "\n",
            "TRUST!\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "**************************************************\n",
            "\n",
            "\n",
            "\n",
            "You are receiving this email as a double opt-in \n",
            "\n",
            "subscriber to the Standard Affiliates Mailing \n",
            "\n",
            "List. \n",
            "\n",
            "To remove yourself from all related email lists,\n",
            "\n",
            "just click here:\n",
            "\n",
            "http://64.123.160.91:81/li/gg/unsubscriber.asp?userid=zzzz@netcomuk.co.uk\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'=================================\\n\\n\\n\\nGuaranteed to increase, lift and firm your\\n\\nbreasts in 60 days or your money back!!\\n\\n\\n\\n100% herbal and natural.  Proven formula since \\n\\n1996.  Increase  your bust by 1 to 3 sizes within 30-60 \\n\\ndays and be all natural.  \\n\\n\\n\\nClick here:\\n\\nhttp://202.101.163.34:81/li/wangxd/\\n\\n\\n\\nAbsolutely no side effects!\\n\\nBe more self confident!\\n\\nBe more comfortable in bed!\\n\\nNo more need for a lift or support bra!\\n\\n\\n\\n100% GUARANTEED AND FROM A NAME YOU KNOW AND \\n\\nTRUST!\\n\\n\\n\\n\\n\\n**************************************************\\n\\n\\n\\nYou are receiving this email as a double opt-in \\n\\nsubscriber to the Standard Affiliates Mailing \\n\\nList. \\n\\nTo remove yourself from all related email lists,\\n\\njust click here:\\n\\nhttp://64.123.160.91:81/li/gg/unsubscriber.asp?userid=zzzz@netcomuk.co.uk\\n\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haznwqE8gD0y",
        "colab_type": "text"
      },
      "source": [
        "Now, let's apply all these techniques to our Data Frame!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4pYBgihgIvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NPL function for e-mail text pre-processing \n",
        "def clean_message(message, stemmer=PorterStemmer(), stop_words= set(stopwords.words('english'))):\n",
        "\n",
        "  filtered_words = [] # our final list\n",
        "\n",
        "  # 1. Remove HTML Tags\n",
        "  soup = BeautifulSoup(message,'html.parser')\n",
        "  cleaned_text = soup.get_text()\n",
        "\n",
        "  # 2. Tokenize and convert to lower case\n",
        "  words = word_tokenize(cleaned_text.lower())\n",
        "\n",
        "  # 3. Remove stop words, punctuations and Stemming the word list for each word in our message\n",
        "  # for each word in our message\n",
        "  for word in words:\n",
        "\n",
        "    # Remove stop words and punctuations\n",
        "    if word not in stop_words and word.isalpha():\n",
        "\n",
        "      # Stemming our word + Append in our final list\n",
        "      filtered_words.append(stemmer.stem(word))\n",
        "\n",
        "  return filtered_words"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsKtvUtnjE5R",
        "colab_type": "text"
      },
      "source": [
        "Now let's apply these NPL techniques to our email dataframe\n",
        "\n",
        "Before we start, we will learn **how to slice dataframes and series & create subsets** in order to make our work easier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynfSvJmGi0Dg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "c658f838-44f1-4e9e-9c7e-8c8c369b88f7"
      },
      "source": [
        "# Slicing dataframes and series & Creating subsets\n",
        "\n",
        "# Slicing >> .iloc[start:stop] Selects more than 1 row sequentially\n",
        "data.iloc[0:2] # Select the first two rows (0 to 2)\n",
        "data.iloc[5:11] # Select the rows from 5 to 11 (5 to 10)\n",
        "\n",
        "first_emails = data.Message.iloc[0:3] # You can specify the column\n",
        "\n",
        "# Apply function >> apply some function to a dataset. In this case we are applying clean_message function to first_emails dataset\n",
        "nested_list = first_emails.apply(clean_message)\n",
        "\n",
        "nested_list"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Doc_ID\n",
              "0    [digit, publish, tool, free, softwar, alert, p...\n",
              "1    [email, market, work, way, around, medium, let...\n",
              "2    [guarante, increas, lift, firm, breast, day, m...\n",
              "Name: Message, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Hv-HyXmkuEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generating all emails in a single list (flattened list)\n",
        "\n",
        "# Solution 1: Traditional form (2x loops + append)\n",
        "#for sublist in nested_list:\n",
        "#  for item in sublist:\n",
        "#    flat_list.append(item)\n",
        "\n",
        "# Solution 2: Using list comprehension syntax (1 line of code, not so readable)\n",
        "flat_list = [item for sublist in nested_list for item in sublist]"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALHKNdyNjZFf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "fe7015a2-3802-4d8e-8783-b38a029ac25a"
      },
      "source": [
        "# Apply our NPL functions to our Dataframe\n",
        "messages_list = data.Message.apply(clean_message)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"http://www.post-gazette.com/columnists/20020905brian5\n",
            "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-3Zs3lmlqao",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b1de3861-7d3e-4534-d943-27117d4ab265"
      },
      "source": [
        "# Slicing data frames using logic\n",
        "\n",
        "# We will create a new dataset with the condition into the []\n",
        "docs_id_spam = data[data.Category == 1].index\n",
        "docs_id_ham = data[data.Category == 0].index\n",
        "\n",
        "\n",
        "# We can retrieved specific indexes with the 'loc' function\n",
        "nested_list_spam = messages_list.loc[docs_id_spam]\n",
        "nested_list_ham = messages_list.loc[docs_id_ham]\n",
        "\n",
        "print('Nested list spam shape:',nested_list_spam.shape)\n",
        "print('Nested list ham shape: ', nested_list_ham.shape)\n"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nested list spam shape: (1896,)\n",
            "Nested list ham shape:  (3901,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1D9YsQmMC6zn",
        "colab_type": "text"
      },
      "source": [
        "Now, Let's check which are the most common words in our dataset. This will be helpful in order to select the most frequent words for spam and not spam emails"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A0aNFdmCgNb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ecfb134b-f234-4ac3-dc1e-d4665b96d7ad"
      },
      "source": [
        "# Checking the most common words in our NOT spam set of words\n",
        "flat_list_ham = [item for sublist in nested_list_ham for item in sublist] # retrieve all data\n",
        "normal_words = pd.Series(flat_list_ham).value_counts() # Create a Panda Series with our list and remove duplicates with value_counts\n",
        "\n",
        "normal_words.shape[0] # total number of words witout duplications >> 20.815\n",
        "\n",
        "normal_words[:10]"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "http      7562\n",
              "use       3632\n",
              "list      2878\n",
              "one       2371\n",
              "get       2286\n",
              "mail      2255\n",
              "would     2003\n",
              "like      1929\n",
              "messag    1847\n",
              "work      1798\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIMr7riDDOwk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "1eef822c-102f-46dc-fbeb-8bd99f380ebc"
      },
      "source": [
        "# Checking the most common words in our spam set of words\n",
        "flat_list_spam = [item for sublist in nested_list_spam for item in sublist] # retrieve all data\n",
        "spam_words = pd.Series(flat_list_spam).value_counts() # Create a Panda Series with our list and remove duplicates with value_counts\n",
        "\n",
        "print(spam_words.shape[0]) # total number of words witout duplications >> 13.242\n",
        "\n",
        "spam_words[:10]"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13280\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "http      3101\n",
              "email     3094\n",
              "free      2555\n",
              "click     2058\n",
              "receiv    1987\n",
              "list      1974\n",
              "get       1903\n",
              "pleas     1842\n",
              "busi      1792\n",
              "order     1743\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXqVoqaWDna1",
        "colab_type": "text"
      },
      "source": [
        "## **Step 5: Creating the vocabulary and dictionary for our spam classifier**\n",
        "\n",
        "Finishing our text pre-processing. There are lots of individual words among the 5.800 odd emails our dataset. We won't use every single word from the email body, we will use an amount of most frequent words (2.500 in our case)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm4zccv4DX-x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "4da8fbd1-0961-429f-bdc6-f55a90bf0a3a"
      },
      "source": [
        "# Generating the Vocabulary from our stemmed words\n",
        "stemmed_nested_list = data.Message.apply(clean_message)\n",
        "\n",
        "# Flatten the stemmed list \n",
        "flat_stemmed_list = [item for sublist in stemmed_nested_list for item in sublist]\n",
        "\n",
        "# Get the unique list of words\n",
        "unique_words = pd.Series(flat_stemmed_list).value_counts()\n",
        "\n",
        "print('Nr of unique words:', unique_words.shape[0]) \n",
        "\n",
        "unique_words.head()\n",
        "\n",
        "frequent_words = unique_words[0:VOCAB_SIZE] # Get the most 2.500 frequent words [begin:end] if not declared is = 0\n",
        "print('Most common 10 words: \\n', frequent_words[:10])\n",
        "\n",
        "# Creating a vocabulary Data Frame with a WORD_ID\n",
        "\n",
        "word_ids = list(range(0,VOCAB_SIZE))\n",
        "\n",
        "vocabulary = pd.DataFrame({'Vocab_Words': frequent_words.index.values}, index= word_ids) #index.values >> get the values from the Series\n",
        "vocabulary.index.name = 'Word_ID'\n",
        "\n",
        "vocabulary.head()\n",
        "\n",
        "# Saving our word list as CSV\n",
        "vocabulary.to_csv(WORD_ID_FILE, index_label=vocabulary.index.name, header=vocabulary.Vocab_Words.name)\n",
        "\n"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"http://www.post-gazette.com/columnists/20020905brian5\n",
            "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Nr of unique words: 27294\n",
            "Most common 10 words: \n",
            " http     10663\n",
            "use       5019\n",
            "list      4852\n",
            "email     4370\n",
            "get       4189\n",
            "mail      3985\n",
            "one       3905\n",
            "free      3171\n",
            "time      3090\n",
            "work      2880\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2T02Bl-ETwC",
        "colab_type": "text"
      },
      "source": [
        "Practicing the techniques we have learnt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BM93ywjmEmfb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c643c20c-16f0-4e83-afe6-53ba0fd98629"
      },
      "source": [
        "## Exercise 1: Check if a word is part of the vocabulary\n",
        "\n",
        "any(vocabulary.Vocab_Words == 'http') # inefficient\n",
        "\n",
        "# Convert our Data frame to a set to become more efficient!\n",
        "print('http' in set(vocabulary.Vocab_Words))\n",
        "\n",
        "\n",
        "## Exercise 2: Print out the number of words in the longest email (after cleaning & stemming)\n",
        "# Note the longest email's position in the list of cleaned emails. Print out the stemmed list of the words from the data frame\n",
        "\n",
        "clean_email_lengths = [] # number of character in each email\n",
        "\n",
        "for sublist in stemmed_nested_list:\n",
        "    \n",
        "    clean_email_lengths.append(len(sublist))\n",
        "    \n",
        "# Alternatively with list comprehension\n",
        "clean_email_lengths = [len(sublist) for sublist in stemmed_nested_list]\n",
        "\n",
        "print('Number of words in the longest email: ', max(clean_email_lengths))\n",
        "print('Email position in the list and the dataframe: ', np.argmax(clean_email_lengths)) # Returns the location in the largest value"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "Number of words in the longest email:  7661\n",
            "Email position in the list and the dataframe:  4815\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ug4eN-dEuGC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "19fa9f60-4874-4fbc-e161-c9fcde5acad0"
      },
      "source": [
        "stemmed_nested_list[np.argmax(clean_email_lengths)] # Collects the index from the biggest value"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['yahoo',\n",
              " 'group',\n",
              " 'sponsor',\n",
              " 'dvd',\n",
              " 'free',\n",
              " 'p',\n",
              " 'join',\n",
              " 'http',\n",
              " 'new',\n",
              " 'version',\n",
              " 'unison',\n",
              " 'avail',\n",
              " 'test',\n",
              " 'incorpor',\n",
              " 'sever',\n",
              " 'small',\n",
              " 'improv',\n",
              " 'main',\n",
              " 'chang',\n",
              " 'fix',\n",
              " 'bug',\n",
              " 'potenti',\n",
              " 'seriou',\n",
              " 'safeti',\n",
              " 'consequ',\n",
              " 'small',\n",
              " 'number',\n",
              " 'user',\n",
              " 'habit',\n",
              " 'run',\n",
              " 'one',\n",
              " 'instanc',\n",
              " 'unison',\n",
              " 'time',\n",
              " 'parallel',\n",
              " 'user',\n",
              " 'strongli',\n",
              " 'encourag',\n",
              " 'upgrad',\n",
              " 'other',\n",
              " 'wait',\n",
              " 'wish',\n",
              " 'releas',\n",
              " 'includ',\n",
              " 'execut',\n",
              " 'linux',\n",
              " 'solari',\n",
              " 'window',\n",
              " 'look',\n",
              " 'maintain',\n",
              " 'moment',\n",
              " 'none',\n",
              " 'activ',\n",
              " 'develop',\n",
              " 'regularli',\n",
              " 'use',\n",
              " 'unison',\n",
              " 'window',\n",
              " 'machin',\n",
              " 'configur',\n",
              " 'properli',\n",
              " 'build',\n",
              " 'execut',\n",
              " 'export',\n",
              " 'grab',\n",
              " 'http',\n",
              " 'enjoy',\n",
              " 'benjamin',\n",
              " 'chang',\n",
              " 'sinc',\n",
              " 'ad',\n",
              " 'prefer',\n",
              " 'maxthread',\n",
              " 'use',\n",
              " 'limit',\n",
              " 'number',\n",
              " 'simultan',\n",
              " 'file',\n",
              " 'transfer',\n",
              " 'ad',\n",
              " 'backupdir',\n",
              " 'prefer',\n",
              " 'control',\n",
              " 'backup',\n",
              " 'file',\n",
              " 'store',\n",
              " 'basic',\n",
              " 'support',\n",
              " 'ad',\n",
              " 'osx',\n",
              " 'particular',\n",
              " 'unison',\n",
              " 'recogn',\n",
              " 'one',\n",
              " 'host',\n",
              " 'synchron',\n",
              " 'run',\n",
              " 'osx',\n",
              " 'switch',\n",
              " 'treatment',\n",
              " 'filenam',\n",
              " 'consid',\n",
              " 'file',\n",
              " 'osx',\n",
              " 'yet',\n",
              " 'fulli',\n",
              " 'work',\n",
              " 'howev',\n",
              " 'particular',\n",
              " 'file',\n",
              " 'resourc',\n",
              " 'fork',\n",
              " 'synchron',\n",
              " 'correctli',\n",
              " 'hash',\n",
              " 'use',\n",
              " 'form',\n",
              " 'archiv',\n",
              " 'name',\n",
              " 'also',\n",
              " 'ad',\n",
              " 'name',\n",
              " 'temp',\n",
              " 'file',\n",
              " 'creat',\n",
              " 'file',\n",
              " 'transfer',\n",
              " 'reason',\n",
              " 'updat',\n",
              " 'detect',\n",
              " 'go',\n",
              " 'silent',\n",
              " 'delet',\n",
              " 'old',\n",
              " 'temp',\n",
              " 'file',\n",
              " 'find',\n",
              " 'along',\n",
              " 'way',\n",
              " 'want',\n",
              " 'prevent',\n",
              " 'delet',\n",
              " 'temp',\n",
              " 'file',\n",
              " 'belong',\n",
              " 'instanc',\n",
              " 'unison',\n",
              " 'may',\n",
              " 'run',\n",
              " 'parallel',\n",
              " 'synchron',\n",
              " 'differ',\n",
              " 'host',\n",
              " 'thank',\n",
              " 'ruslan',\n",
              " 'ermilov',\n",
              " 'suggest',\n",
              " 'sever',\n",
              " 'small',\n",
              " 'user',\n",
              " 'interfac',\n",
              " 'improv',\n",
              " 'document',\n",
              " 'faq',\n",
              " 'bug',\n",
              " 'report',\n",
              " 'instruct',\n",
              " 'split',\n",
              " 'separ',\n",
              " 'html',\n",
              " 'page',\n",
              " 'access',\n",
              " 'directli',\n",
              " 'unison',\n",
              " 'web',\n",
              " 'page',\n",
              " 'addit',\n",
              " 'faq',\n",
              " 'particular',\n",
              " 'suggest',\n",
              " 'perform',\n",
              " 'tune',\n",
              " 'makefil',\n",
              " 'set',\n",
              " 'automat',\n",
              " 'depend',\n",
              " 'whether',\n",
              " 'find',\n",
              " 'lablgtk',\n",
              " 'instal',\n",
              " 'unison',\n",
              " 'compil',\n",
              " 'box',\n",
              " 'osx',\n",
              " 'chang',\n",
              " 'sinc',\n",
              " 'chang',\n",
              " 'profil',\n",
              " 'work',\n",
              " 'window',\n",
              " 'file',\n",
              " 'movement',\n",
              " 'optim',\n",
              " 'unison',\n",
              " 'tri',\n",
              " 'use',\n",
              " 'local',\n",
              " 'copi',\n",
              " 'instead',\n",
              " 'transfer',\n",
              " 'move',\n",
              " 'copi',\n",
              " 'file',\n",
              " 'control',\n",
              " 'boolean',\n",
              " 'option',\n",
              " 'xferbycopi',\n",
              " 'network',\n",
              " 'statist',\n",
              " 'window',\n",
              " 'transfer',\n",
              " 'rate',\n",
              " 'amount',\n",
              " 'data',\n",
              " 'transfer',\n",
              " 'nb',\n",
              " 'avail',\n",
              " 'version',\n",
              " 'symlink',\n",
              " 'work',\n",
              " 'cygwin',\n",
              " 'version',\n",
              " 'dynam',\n",
              " 'link',\n",
              " 'fix',\n",
              " 'potenti',\n",
              " 'deadlock',\n",
              " 'synchron',\n",
              " 'window',\n",
              " 'unix',\n",
              " 'small',\n",
              " 'improv',\n",
              " 'neither',\n",
              " 'tt',\n",
              " 'userprofil',\n",
              " 'tt',\n",
              " 'home',\n",
              " 'environ',\n",
              " 'variabl',\n",
              " 'set',\n",
              " 'unison',\n",
              " 'put',\n",
              " 'temporari',\n",
              " 'commit',\n",
              " 'log',\n",
              " 'call',\n",
              " 'tt',\n",
              " 'directori',\n",
              " 'name',\n",
              " 'tt',\n",
              " 'unison',\n",
              " 'environ',\n",
              " 'variabl',\n",
              " 'otherwis',\n",
              " 'use',\n",
              " 'tt',\n",
              " 'c',\n",
              " 'altern',\n",
              " 'set',\n",
              " 'valu',\n",
              " 'fastcheck',\n",
              " 'ye',\n",
              " 'true',\n",
              " 'fals',\n",
              " 'default',\n",
              " 'auto',\n",
              " 'impli',\n",
              " 'sourc',\n",
              " 'code',\n",
              " 'code',\n",
              " 'reorgan',\n",
              " 'tidi',\n",
              " 'start',\n",
              " 'break',\n",
              " 'basic',\n",
              " 'util',\n",
              " 'modul',\n",
              " 'stuff',\n",
              " 'made',\n",
              " 'avail',\n",
              " 'project',\n",
              " 'sever',\n",
              " 'makefil',\n",
              " 'doc',\n",
              " 'chang',\n",
              " 'releas',\n",
              " 'comment',\n",
              " 'connect',\n",
              " 'inform',\n",
              " 'store',\n",
              " 'global',\n",
              " 'variabl',\n",
              " 'anymor',\n",
              " 'chang',\n",
              " 'sinc',\n",
              " 'small',\n",
              " 'bugfix',\n",
              " 'textual',\n",
              " 'user',\n",
              " 'interfac',\n",
              " 'unix',\n",
              " 'avoid',\n",
              " 'leav',\n",
              " 'termin',\n",
              " 'bad',\n",
              " 'state',\n",
              " 'would',\n",
              " 'echo',\n",
              " 'input',\n",
              " 'unison',\n",
              " 'exit',\n",
              " 'chang',\n",
              " 'sinc',\n",
              " 'improv',\n",
              " 'main',\n",
              " 'web',\n",
              " 'page',\n",
              " 'stabl',\n",
              " 'beta',\n",
              " 'version',\n",
              " 'doc',\n",
              " 'access',\n",
              " 'user',\n",
              " 'manual',\n",
              " 'revis',\n",
              " 'ad',\n",
              " 'new',\n",
              " 'prefer',\n",
              " 'sshcmd',\n",
              " 'rshcmd',\n",
              " 'specifi',\n",
              " 'path',\n",
              " 'ssh',\n",
              " 'rsh',\n",
              " 'program',\n",
              " 'contactquietli',\n",
              " 'suppress',\n",
              " 'contact',\n",
              " 'server',\n",
              " 'messag',\n",
              " 'unison',\n",
              " 'startup',\n",
              " 'graphic',\n",
              " 'ui',\n",
              " 'bug',\n",
              " 'fix',\n",
              " 'fix',\n",
              " 'small',\n",
              " 'bug',\n",
              " 'ui',\n",
              " 'neglect',\n",
              " 'chang',\n",
              " 'display',\n",
              " 'column',\n",
              " 'header',\n",
              " 'load',\n",
              " 'new',\n",
              " 'profil',\n",
              " 'caus',\n",
              " 'root',\n",
              " 'chang',\n",
              " 'fix',\n",
              " 'bug',\n",
              " 'would',\n",
              " 'put',\n",
              " 'text',\n",
              " 'ui',\n",
              " 'infinit',\n",
              " 'loop',\n",
              " 'encount',\n",
              " 'conflict',\n",
              " 'run',\n",
              " 'batch',\n",
              " 'mode',\n",
              " 'ad',\n",
              " 'code',\n",
              " 'tri',\n",
              " 'fix',\n",
              " 'display',\n",
              " 'charact',\n",
              " 'filenam',\n",
              " 'window',\n",
              " 'system',\n",
              " 'gtk',\n",
              " 'ui',\n",
              " 'code',\n",
              " 'current',\n",
              " 'untest',\n",
              " 'one',\n",
              " 'peopl',\n",
              " 'report',\n",
              " 'problem',\n",
              " 'display',\n",
              " 'filenam',\n",
              " 'appreci',\n",
              " 'know',\n",
              " 'actual',\n",
              " 'fix',\n",
              " 'thing',\n",
              " 'newer',\n",
              " 'work',\n",
              " 'properli',\n",
              " 'bug',\n",
              " 'report',\n",
              " 'sebastian',\n",
              " 'urbaniak',\n",
              " 'sean',\n",
              " 'fulton',\n",
              " 'user',\n",
              " 'interfac',\n",
              " 'unison',\n",
              " 'behavior',\n",
              " 'renam',\n",
              " 'graphic',\n",
              " 'ui',\n",
              " 'ad',\n",
              " 'exit',\n",
              " 'statu',\n",
              " 'textual',\n",
              " 'user',\n",
              " 'interfac',\n",
              " 'path',\n",
              " 'synchron',\n",
              " 'conflict',\n",
              " 'error',\n",
              " 'updat',\n",
              " 'detect',\n",
              " 'note',\n",
              " 'log',\n",
              " 'file',\n",
              " 'end',\n",
              " 'messag',\n",
              " 'log',\n",
              " 'use',\n",
              " 'briefer',\n",
              " 'format',\n",
              " 'chang',\n",
              " 'text',\n",
              " 'ui',\n",
              " 'startup',\n",
              " 'sequenc',\n",
              " 'tt',\n",
              " 'text',\n",
              " 'use',\n",
              " 'default',\n",
              " 'profil',\n",
              " 'instead',\n",
              " 'fail',\n",
              " 'made',\n",
              " 'improv',\n",
              " 'error',\n",
              " 'messag',\n",
              " 'ad',\n",
              " 'debug',\n",
              " 'messag',\n",
              " 'chang',\n",
              " 'sinc',\n",
              " 'incorpor',\n",
              " 'transport',\n",
              " 'transfer',\n",
              " 'sever',\n",
              " 'file',\n",
              " 'time',\n",
              " 'therebi',\n",
              " 'make',\n",
              " 'much',\n",
              " 'effect',\n",
              " 'use',\n",
              " 'avail',\n",
              " 'network',\n",
              " 'bandwidth',\n",
              " 'unlik',\n",
              " 'earlier',\n",
              " 'attempt',\n",
              " 'time',\n",
              " 'reli',\n",
              " 'nativ',\n",
              " 'thread',\n",
              " 'librari',\n",
              " 'ocaml',\n",
              " 'instead',\n",
              " 'implement',\n",
              " 'librari',\n",
              " 'ocaml',\n",
              " 'directli',\n",
              " 'version',\n",
              " 'appear',\n",
              " 'stabl',\n",
              " 'adjust',\n",
              " 'unison',\n",
              " 'made',\n",
              " 'accommod',\n",
              " 'version',\n",
              " 'includ',\n",
              " 'particular',\n",
              " 'chang',\n",
              " 'user',\n",
              " 'interfac',\n",
              " 'log',\n",
              " 'exampl',\n",
              " 'two',\n",
              " 'log',\n",
              " 'entri',\n",
              " 'transfer',\n",
              " 'task',\n",
              " 'one',\n",
              " 'begin',\n",
              " 'one',\n",
              " 'end',\n",
              " 'suppress',\n",
              " 'warn',\n",
              " 'messag',\n",
              " 'remov',\n",
              " 'temp',\n",
              " 'file',\n",
              " 'left',\n",
              " 'previou',\n",
              " 'unison',\n",
              " 'run',\n",
              " 'warn',\n",
              " 'work',\n",
              " 'nice',\n",
              " 'temp',\n",
              " 'file',\n",
              " 'name',\n",
              " 'made',\n",
              " 'less',\n",
              " 'like',\n",
              " 'coincid',\n",
              " 'name',\n",
              " 'file',\n",
              " 'creat',\n",
              " 'user',\n",
              " 'take',\n",
              " 'form',\n",
              " 'ad',\n",
              " 'new',\n",
              " 'command',\n",
              " 'gtk',\n",
              " 'user',\n",
              " 'interfac',\n",
              " 'press',\n",
              " 'caus',\n",
              " 'unison',\n",
              " 'start',\n",
              " 'new',\n",
              " 'updat',\n",
              " 'detect',\n",
              " 'phase',\n",
              " 'use',\n",
              " 'path',\n",
              " 'path',\n",
              " 'detect',\n",
              " 'chang',\n",
              " 'yet',\n",
              " 'mark',\n",
              " 'success',\n",
              " 'complet',\n",
              " 'use',\n",
              " 'command',\n",
              " 'quickli',\n",
              " 'restart',\n",
              " 'unison',\n",
              " 'set',\n",
              " 'path',\n",
              " 'still',\n",
              " 'need',\n",
              " 'attent',\n",
              " 'previou',\n",
              " 'run',\n",
              " 'made',\n",
              " 'ignorecas',\n",
              " 'prefer',\n",
              " 'chang',\n",
              " 'initi',\n",
              " 'code',\n",
              " 'manual',\n",
              " 'set',\n",
              " 'true',\n",
              " 'even',\n",
              " 'neither',\n",
              " 'host',\n",
              " 'run',\n",
              " 'window',\n",
              " 'may',\n",
              " 'use',\n",
              " 'use',\n",
              " 'unison',\n",
              " 'run',\n",
              " 'unix',\n",
              " 'system',\n",
              " 'fat',\n",
              " 'volum',\n",
              " 'mount',\n",
              " 'small',\n",
              " 'improv',\n",
              " 'bug',\n",
              " 'fix',\n",
              " 'error',\n",
              " 'prefer',\n",
              " 'file',\n",
              " 'gener',\n",
              " 'fatal',\n",
              " 'error',\n",
              " 'rather',\n",
              " 'warn',\n",
              " 'startup',\n",
              " 'time',\n",
              " 'ca',\n",
              " 'go',\n",
              " 'also',\n",
              " 'fix',\n",
              " 'bug',\n",
              " 'prevent',\n",
              " 'warn',\n",
              " 'appear',\n",
              " 'text',\n",
              " 'ui',\n",
              " 'user',\n",
              " 'run',\n",
              " 'unsuspectingli',\n",
              " 'garbag',\n",
              " 'pref',\n",
              " 'file',\n",
              " 'may',\n",
              " 'get',\n",
              " 'error',\n",
              " 'report',\n",
              " 'error',\n",
              " 'report',\n",
              " 'prefer',\n",
              " 'file',\n",
              " 'provid',\n",
              " 'file',\n",
              " 'name',\n",
              " 'line',\n",
              " 'number',\n",
              " 'intellig',\n",
              " 'messag',\n",
              " 'case',\n",
              " 'ident',\n",
              " 'chang',\n",
              " 'file',\n",
              " 'noth',\n",
              " 'replica',\n",
              " 'chang',\n",
              " 'ident',\n",
              " 'way',\n",
              " 'sinc',\n",
              " 'last',\n",
              " 'sync',\n",
              " 'file',\n",
              " 'prefix',\n",
              " 'exclud',\n",
              " 'scan',\n",
              " 'prefer',\n",
              " 'file',\n",
              " 'rsync',\n",
              " 'instruct',\n",
              " 'send',\n",
              " 'directli',\n",
              " 'instead',\n",
              " 'first',\n",
              " 'marshal',\n",
              " 'wo',\n",
              " 'tri',\n",
              " 'forev',\n",
              " 'get',\n",
              " 'fingerprint',\n",
              " 'continu',\n",
              " 'chang',\n",
              " 'file',\n",
              " 'unison',\n",
              " 'give',\n",
              " 'certain',\n",
              " 'number',\n",
              " 'retri',\n",
              " 'bug',\n",
              " 'fix',\n",
              " 'includ',\n",
              " 'one',\n",
              " 'report',\n",
              " 'peter',\n",
              " 'seling',\n",
              " 'prefer',\n",
              " 'work',\n",
              " 'compil',\n",
              " 'upgrad',\n",
              " 'new',\n",
              " 'ocaml',\n",
              " 'compil',\n",
              " 'lablgtk',\n",
              " 'librari',\n",
              " 'patch',\n",
              " 'version',\n",
              " 'use',\n",
              " 'compil',\n",
              " 'window',\n",
              " 'ad',\n",
              " 'option',\n",
              " 'compil',\n",
              " 'unison',\n",
              " 'window',\n",
              " 'platform',\n",
              " 'cygwin',\n",
              " 'gnu',\n",
              " 'c',\n",
              " 'compil',\n",
              " 'option',\n",
              " 'support',\n",
              " 'build',\n",
              " 'dynam',\n",
              " 'link',\n",
              " 'unison',\n",
              " 'execut',\n",
              " 'chang',\n",
              " 'sinc',\n",
              " 'fix',\n",
              " 'silli',\n",
              " 'debilit',\n",
              " 'bug',\n",
              " 'client',\n",
              " 'startup',\n",
              " 'sequenc',\n",
              " 'chang',\n",
              " 'sinc',\n",
              " 'ad',\n",
              " 'addprefsto',\n",
              " 'prefer',\n",
              " 'set',\n",
              " 'control',\n",
              " 'prefer',\n",
              " 'file',\n",
              " 'new',\n",
              " 'prefer',\n",
              " 'new',\n",
              " 'ignor',\n",
              " 'pattern',\n",
              " 'ad',\n",
              " 'bug',\n",
              " 'fix',\n",
              " 'read',\n",
              " 'initi',\n",
              " 'connect',\n",
              " 'header',\n",
              " 'one',\n",
              " 'byte',\n",
              " 'time',\n",
              " 'block',\n",
              " 'header',\n",
              " 'shorter',\n",
              " 'expect',\n",
              " 'bug',\n",
              " 'affect',\n",
              " 'normal',\n",
              " 'oper',\n",
              " 'made',\n",
              " 'hard',\n",
              " 'tell',\n",
              " 'tri',\n",
              " 'use',\n",
              " 'unison',\n",
              " 'incorrectli',\n",
              " 'old',\n",
              " 'version',\n",
              " 'server',\n",
              " 'sinc',\n",
              " 'would',\n",
              " 'hang',\n",
              " 'instead',\n",
              " 'give',\n",
              " 'error',\n",
              " 'messag',\n",
              " 'chang',\n",
              " 'sinc',\n",
              " 'chang',\n",
              " 'fastcheck',\n",
              " 'boolean',\n",
              " 'string',\n",
              " 'prefer',\n",
              " 'legal',\n",
              " 'valu',\n",
              " 'ye',\n",
              " 'fast',\n",
              " 'check',\n",
              " 'safe',\n",
              " 'check',\n",
              " 'default',\n",
              " 'fast',\n",
              " 'check',\n",
              " 'also',\n",
              " 'happen',\n",
              " 'safe',\n",
              " 'run',\n",
              " 'unix',\n",
              " 'safe',\n",
              " 'check',\n",
              " 'window',\n",
              " 'default',\n",
              " 'default',\n",
              " 'sever',\n",
              " 'prefer',\n",
              " 'renam',\n",
              " 'consist',\n",
              " 'prefer',\n",
              " 'name',\n",
              " 'spell',\n",
              " 'lowercas',\n",
              " 'backward',\n",
              " 'compat',\n",
              " 'old',\n",
              " 'name',\n",
              " 'still',\n",
              " 'work',\n",
              " 'mention',\n",
              " 'manual',\n",
              " 'temp',\n",
              " 'file',\n",
              " 'creat',\n",
              " 'command',\n",
              " 'name',\n",
              " 'prepend',\n",
              " 'new',\n",
              " 'prefix',\n",
              " 'file',\n",
              " 'name',\n",
              " 'rather',\n",
              " 'append',\n",
              " 'suffix',\n",
              " 'avoid',\n",
              " 'confus',\n",
              " 'program',\n",
              " 'depend',\n",
              " 'suffix',\n",
              " 'guess',\n",
              " 'type',\n",
              " 'file',\n",
              " 'content',\n",
              " 'set',\n",
              " 'keepal',\n",
              " 'option',\n",
              " 'server',\n",
              " 'socket',\n",
              " 'make',\n",
              " 'sure',\n",
              " 'server',\n",
              " 'time',\n",
              " 'commun',\n",
              " 'link',\n",
              " 'unexpectedli',\n",
              " 'broken',\n",
              " 'bug',\n",
              " 'fix',\n",
              " 'updat',\n",
              " 'small',\n",
              " 'file',\n",
              " 'unison',\n",
              " 'close',\n",
              " 'destin',\n",
              " 'file',\n",
              " 'file',\n",
              " 'permiss',\n",
              " 'properli',\n",
              " 'updat',\n",
              " 'file',\n",
              " 'behind',\n",
              " 'follow',\n",
              " 'link',\n",
              " 'sever',\n",
              " 'small',\n",
              " 'fix',\n",
              " 'chang',\n",
              " 'sinc',\n",
              " 'major',\n",
              " 'window',\n",
              " 'perform',\n",
              " 'improv',\n",
              " 'ad',\n",
              " 'prefer',\n",
              " 'fastcheck',\n",
              " 'make',\n",
              " 'unison',\n",
              " 'look',\n",
              " 'file',\n",
              " 'creation',\n",
              " 'time',\n",
              " 'time',\n",
              " 'check',\n",
              " 'whether',\n",
              " 'chang',\n",
              " 'result',\n",
              " 'huge',\n",
              " 'speedup',\n",
              " 'check',\n",
              " 'updat',\n",
              " 'larg',\n",
              " 'replica',\n",
              " 'switch',\n",
              " 'set',\n",
              " 'unison',\n",
              " 'use',\n",
              " 'file',\n",
              " 'creation',\n",
              " 'time',\n",
              " 'inod',\n",
              " 'number',\n",
              " 'scan',\n",
              " 'window',\n",
              " 'replica',\n",
              " 'updat',\n",
              " 'instead',\n",
              " 'read',\n",
              " 'full',\n",
              " 'content',\n",
              " 'everi',\n",
              " 'file',\n",
              " 'may',\n",
              " 'caus',\n",
              " 'unison',\n",
              " 'miss',\n",
              " 'propag',\n",
              " 'updat',\n",
              " 'creat',\n",
              " 'time',\n",
              " 'modif',\n",
              " 'time',\n",
              " 'length',\n",
              " 'file',\n",
              " 'unchang',\n",
              " 'updat',\n",
              " 'easi',\n",
              " 'achiev',\n",
              " 'done',\n",
              " 'howev',\n",
              " 'unison',\n",
              " 'never',\n",
              " 'overwrit',\n",
              " 'updat',\n",
              " 'chang',\n",
              " 'replica',\n",
              " 'sinc',\n",
              " 'alway',\n",
              " 'safe',\n",
              " 'check',\n",
              " 'updat',\n",
              " 'propag',\n",
              " 'chang',\n",
              " 'thu',\n",
              " 'reason',\n",
              " 'use',\n",
              " 'switch',\n",
              " 'time',\n",
              " 'occasion',\n",
              " 'run',\n",
              " 'unison',\n",
              " 'fastcheck',\n",
              " 'set',\n",
              " 'fals',\n",
              " 'worri',\n",
              " 'unison',\n",
              " 'may',\n",
              " 'overlook',\n",
              " 'updat',\n",
              " 'warn',\n",
              " 'chang',\n",
              " 'yet',\n",
              " 'thoroughli',\n",
              " 'set',\n",
              " 'fastcheck',\n",
              " 'prefer',\n",
              " 'pay',\n",
              " 'care',\n",
              " 'attent',\n",
              " 'unison',\n",
              " 'new',\n",
              " 'function',\n",
              " 'central',\n",
              " 'backup',\n",
              " 'merg',\n",
              " 'version',\n",
              " 'incorpor',\n",
              " 'two',\n",
              " 'piec',\n",
              " 'major',\n",
              " 'new',\n",
              " 'function',\n",
              " 'implement',\n",
              " 'sylvain',\n",
              " 'roy',\n",
              " 'summer',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPlkAJZjE1eP",
        "colab_type": "text"
      },
      "source": [
        "## **Step 6: Sparse Matrix** \n",
        "\n",
        "This is an excellend data structure for Machine Learning data frames\n",
        "\n",
        "With this sort of Matrix we will exclude zeroed data. In our example, we will use words that occurs in spam / not spam emails, acting like a compressed version\n",
        "\n",
        "In our example, each word will be placed with a label if it is spam or not and some level of occurence, and some words are zeros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYaclqbUFFhp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7073857d-c40c-4367-ec3b-47b3c6d2ce80"
      },
      "source": [
        "type(stemmed_nested_list[2]) # It is a DF with multiple lists in each index."
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qdei7uGjFIVo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "d5189018-e251-46ad-b0a6-e7fa24893544"
      },
      "source": [
        "word_columns_df = pd.DataFrame.from_records(stemmed_nested_list.to_list()) # Transforming each word in a column as individual data point\n",
        "word_columns_df.head()\n",
        "\n",
        "# Df Shape: 5796 (emails that we have) x 7671 (number of words in the longest email)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>7621</th>\n",
              "      <th>7622</th>\n",
              "      <th>7623</th>\n",
              "      <th>7624</th>\n",
              "      <th>7625</th>\n",
              "      <th>7626</th>\n",
              "      <th>7627</th>\n",
              "      <th>7628</th>\n",
              "      <th>7629</th>\n",
              "      <th>7630</th>\n",
              "      <th>7631</th>\n",
              "      <th>7632</th>\n",
              "      <th>7633</th>\n",
              "      <th>7634</th>\n",
              "      <th>7635</th>\n",
              "      <th>7636</th>\n",
              "      <th>7637</th>\n",
              "      <th>7638</th>\n",
              "      <th>7639</th>\n",
              "      <th>7640</th>\n",
              "      <th>7641</th>\n",
              "      <th>7642</th>\n",
              "      <th>7643</th>\n",
              "      <th>7644</th>\n",
              "      <th>7645</th>\n",
              "      <th>7646</th>\n",
              "      <th>7647</th>\n",
              "      <th>7648</th>\n",
              "      <th>7649</th>\n",
              "      <th>7650</th>\n",
              "      <th>7651</th>\n",
              "      <th>7652</th>\n",
              "      <th>7653</th>\n",
              "      <th>7654</th>\n",
              "      <th>7655</th>\n",
              "      <th>7656</th>\n",
              "      <th>7657</th>\n",
              "      <th>7658</th>\n",
              "      <th>7659</th>\n",
              "      <th>7660</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>digit</td>\n",
              "      <td>publish</td>\n",
              "      <td>tool</td>\n",
              "      <td>free</td>\n",
              "      <td>softwar</td>\n",
              "      <td>alert</td>\n",
              "      <td>publish</td>\n",
              "      <td>like</td>\n",
              "      <td>profession</td>\n",
              "      <td>digit</td>\n",
              "      <td>publish</td>\n",
              "      <td>tool</td>\n",
              "      <td>easili</td>\n",
              "      <td>creat</td>\n",
              "      <td>profession</td>\n",
              "      <td>ebook</td>\n",
              "      <td>ebrochur</td>\n",
              "      <td>ecatalog</td>\n",
              "      <td>resum</td>\n",
              "      <td>newslett</td>\n",
              "      <td>present</td>\n",
              "      <td>magazin</td>\n",
              "      <td>photo</td>\n",
              "      <td>album</td>\n",
              "      <td>invit</td>\n",
              "      <td>much</td>\n",
              "      <td>much</td>\n",
              "      <td>save</td>\n",
              "      <td>money</td>\n",
              "      <td>save</td>\n",
              "      <td>tree</td>\n",
              "      <td>save</td>\n",
              "      <td>print</td>\n",
              "      <td>postag</td>\n",
              "      <td>advertis</td>\n",
              "      <td>cost</td>\n",
              "      <td>digit</td>\n",
              "      <td>publish</td>\n",
              "      <td>tool</td>\n",
              "      <td>download</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>email</td>\n",
              "      <td>market</td>\n",
              "      <td>work</td>\n",
              "      <td>way</td>\n",
              "      <td>around</td>\n",
              "      <td>medium</td>\n",
              "      <td>let</td>\n",
              "      <td>share</td>\n",
              "      <td>offer</td>\n",
              "      <td>peopl</td>\n",
              "      <td>less</td>\n",
              "      <td>cost</td>\n",
              "      <td>small</td>\n",
              "      <td>classifi</td>\n",
              "      <td>ad</td>\n",
              "      <td>get</td>\n",
              "      <td>access</td>\n",
              "      <td>target</td>\n",
              "      <td>email</td>\n",
              "      <td>list</td>\n",
              "      <td>exchang</td>\n",
              "      <td>member</td>\n",
              "      <td>exchang</td>\n",
              "      <td>old</td>\n",
              "      <td>target</td>\n",
              "      <td>email</td>\n",
              "      <td>list</td>\n",
              "      <td>new</td>\n",
              "      <td>one</td>\n",
              "      <td>get</td>\n",
              "      <td>access</td>\n",
              "      <td>million</td>\n",
              "      <td>fresh</td>\n",
              "      <td>gener</td>\n",
              "      <td>email</td>\n",
              "      <td>everi</td>\n",
              "      <td>week</td>\n",
              "      <td>offer</td>\n",
              "      <td>servic</td>\n",
              "      <td>free</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>guarante</td>\n",
              "      <td>increas</td>\n",
              "      <td>lift</td>\n",
              "      <td>firm</td>\n",
              "      <td>breast</td>\n",
              "      <td>day</td>\n",
              "      <td>money</td>\n",
              "      <td>back</td>\n",
              "      <td>herbal</td>\n",
              "      <td>natur</td>\n",
              "      <td>proven</td>\n",
              "      <td>formula</td>\n",
              "      <td>sinc</td>\n",
              "      <td>increas</td>\n",
              "      <td>bust</td>\n",
              "      <td>size</td>\n",
              "      <td>within</td>\n",
              "      <td>day</td>\n",
              "      <td>natur</td>\n",
              "      <td>click</td>\n",
              "      <td>http</td>\n",
              "      <td>absolut</td>\n",
              "      <td>side</td>\n",
              "      <td>effect</td>\n",
              "      <td>self</td>\n",
              "      <td>confid</td>\n",
              "      <td>comfort</td>\n",
              "      <td>bed</td>\n",
              "      <td>need</td>\n",
              "      <td>lift</td>\n",
              "      <td>support</td>\n",
              "      <td>bra</td>\n",
              "      <td>guarante</td>\n",
              "      <td>name</td>\n",
              "      <td>know</td>\n",
              "      <td>trust</td>\n",
              "      <td>receiv</td>\n",
              "      <td>email</td>\n",
              "      <td>doubl</td>\n",
              "      <td>subscrib</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>like</td>\n",
              "      <td>sexi</td>\n",
              "      <td>anim</td>\n",
              "      <td>wild</td>\n",
              "      <td>thing</td>\n",
              "      <td>super</td>\n",
              "      <td>hot</td>\n",
              "      <td>content</td>\n",
              "      <td>internet</td>\n",
              "      <td>site</td>\n",
              "      <td>heard</td>\n",
              "      <td>rate</td>\n",
              "      <td>number</td>\n",
              "      <td>one</td>\n",
              "      <td>adult</td>\n",
              "      <td>site</td>\n",
              "      <td>three</td>\n",
              "      <td>year</td>\n",
              "      <td>row</td>\n",
              "      <td>thousand</td>\n",
              "      <td>pic</td>\n",
              "      <td>hardcor</td>\n",
              "      <td>fuck</td>\n",
              "      <td>cum</td>\n",
              "      <td>shot</td>\n",
              "      <td>pet</td>\n",
              "      <td>girl</td>\n",
              "      <td>thousand</td>\n",
              "      <td>video</td>\n",
              "      <td>wait</td>\n",
              "      <td>click</td>\n",
              "      <td>must</td>\n",
              "      <td>least</td>\n",
              "      <td>enter</td>\n",
              "      <td>receiv</td>\n",
              "      <td>advertis</td>\n",
              "      <td>opt</td>\n",
              "      <td>receiv</td>\n",
              "      <td>free</td>\n",
              "      <td>adult</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cell</td>\n",
              "      <td>booster</td>\n",
              "      <td>antenna</td>\n",
              "      <td>boost</td>\n",
              "      <td>recept</td>\n",
              "      <td>cell</td>\n",
              "      <td>phone</td>\n",
              "      <td>cordless</td>\n",
              "      <td>clariti</td>\n",
              "      <td>buy</td>\n",
              "      <td>anoth</td>\n",
              "      <td>phone</td>\n",
              "      <td>bad</td>\n",
              "      <td>recepiton</td>\n",
              "      <td>improv</td>\n",
              "      <td>commun</td>\n",
              "      <td>instantli</td>\n",
              "      <td>simpli</td>\n",
              "      <td>instal</td>\n",
              "      <td>small</td>\n",
              "      <td>chip</td>\n",
              "      <td>power</td>\n",
              "      <td>recept</td>\n",
              "      <td>booster</td>\n",
              "      <td>save</td>\n",
              "      <td>seen</td>\n",
              "      <td>product</td>\n",
              "      <td>compar</td>\n",
              "      <td>transpar</td>\n",
              "      <td>instal</td>\n",
              "      <td>second</td>\n",
              "      <td>power</td>\n",
              "      <td>antenna</td>\n",
              "      <td>drop</td>\n",
              "      <td>interrupt</td>\n",
              "      <td>call</td>\n",
              "      <td>work</td>\n",
              "      <td>place</td>\n",
              "      <td>singal</td>\n",
              "      <td>may</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  7661 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0        1        2      3        4     ...  7656  7657  7658  7659  7660\n",
              "0     digit  publish     tool   free  softwar  ...  None  None  None  None  None\n",
              "1     email   market     work    way   around  ...  None  None  None  None  None\n",
              "2  guarante  increas     lift   firm   breast  ...  None  None  None  None  None\n",
              "3      like     sexi     anim   wild    thing  ...  None  None  None  None  None\n",
              "4      cell  booster  antenna  boost   recept  ...  None  None  None  None  None\n",
              "\n",
              "[5 rows x 7661 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbfvG1lPFQxS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting the data into a training and testing data set\n",
        "\n",
        "# Important: We will shuffle our DF in order to create this subsets\n",
        "# Important 2: Try to use Validation + Test sets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(word_columns_df, data.Category, test_size= 0.3, random_state= 42) # random state = seed value\n"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vcywCOiFckN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "26a64ca6-9815-41cc-ae9a-a192e27735f1"
      },
      "source": [
        "X_train.index.name = X_test.index.name = 'DOC_ID'\n",
        "X_train.head()"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>7621</th>\n",
              "      <th>7622</th>\n",
              "      <th>7623</th>\n",
              "      <th>7624</th>\n",
              "      <th>7625</th>\n",
              "      <th>7626</th>\n",
              "      <th>7627</th>\n",
              "      <th>7628</th>\n",
              "      <th>7629</th>\n",
              "      <th>7630</th>\n",
              "      <th>7631</th>\n",
              "      <th>7632</th>\n",
              "      <th>7633</th>\n",
              "      <th>7634</th>\n",
              "      <th>7635</th>\n",
              "      <th>7636</th>\n",
              "      <th>7637</th>\n",
              "      <th>7638</th>\n",
              "      <th>7639</th>\n",
              "      <th>7640</th>\n",
              "      <th>7641</th>\n",
              "      <th>7642</th>\n",
              "      <th>7643</th>\n",
              "      <th>7644</th>\n",
              "      <th>7645</th>\n",
              "      <th>7646</th>\n",
              "      <th>7647</th>\n",
              "      <th>7648</th>\n",
              "      <th>7649</th>\n",
              "      <th>7650</th>\n",
              "      <th>7651</th>\n",
              "      <th>7652</th>\n",
              "      <th>7653</th>\n",
              "      <th>7654</th>\n",
              "      <th>7655</th>\n",
              "      <th>7656</th>\n",
              "      <th>7657</th>\n",
              "      <th>7658</th>\n",
              "      <th>7659</th>\n",
              "      <th>7660</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DOC_ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2890</th>\n",
              "      <td>mon</td>\n",
              "      <td>sep</td>\n",
              "      <td>rick</td>\n",
              "      <td>rick</td>\n",
              "      <td>baartman</td>\n",
              "      <td>wrote</td>\n",
              "      <td>rick</td>\n",
              "      <td>danger</td>\n",
              "      <td>rememb</td>\n",
              "      <td>rick</td>\n",
              "      <td>folder</td>\n",
              "      <td>enter</td>\n",
              "      <td>safeguard</td>\n",
              "      <td>nope</td>\n",
              "      <td>regener</td>\n",
              "      <td>cach</td>\n",
              "      <td>script</td>\n",
              "      <td>f</td>\n",
              "      <td>echo</td>\n",
              "      <td>sort</td>\n",
              "      <td>f</td>\n",
              "      <td>sortm</td>\n",
              "      <td>f</td>\n",
              "      <td>scan</td>\n",
              "      <td>done</td>\n",
              "      <td>hal</td>\n",
              "      <td>mail</td>\n",
              "      <td>list</td>\n",
              "      <td>http</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5070</th>\n",
              "      <td>adam</td>\n",
              "      <td>beberg</td>\n",
              "      <td>write</td>\n",
              "      <td>interestingli</td>\n",
              "      <td>vc</td>\n",
              "      <td>convinc</td>\n",
              "      <td>zope</td>\n",
              "      <td>go</td>\n",
              "      <td>opensourc</td>\n",
              "      <td>wasnt</td>\n",
              "      <td>realiz</td>\n",
              "      <td>open</td>\n",
              "      <td>sourc</td>\n",
              "      <td>tm</td>\n",
              "      <td>ment</td>\n",
              "      <td>couldnt</td>\n",
              "      <td>control</td>\n",
              "      <td>go</td>\n",
              "      <td>assum</td>\n",
              "      <td>stupid</td>\n",
              "      <td>assum</td>\n",
              "      <td>still</td>\n",
              "      <td>stupid</td>\n",
              "      <td>never</td>\n",
              "      <td>realiz</td>\n",
              "      <td>karl</td>\n",
              "      <td>anderson</td>\n",
              "      <td>kra</td>\n",
              "      <td>http</td>\n",
              "      <td>http</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1293</th>\n",
              "      <td>thought</td>\n",
              "      <td>order</td>\n",
              "      <td>mortgat</td>\n",
              "      <td>loan</td>\n",
              "      <td>offic</td>\n",
              "      <td>graduat</td>\n",
              "      <td>colleg</td>\n",
              "      <td>certifi</td>\n",
              "      <td>licens</td>\n",
              "      <td>bond</td>\n",
              "      <td>think</td>\n",
              "      <td>messag</td>\n",
              "      <td>come</td>\n",
              "      <td>result</td>\n",
              "      <td>relationship</td>\n",
              "      <td>client</td>\n",
              "      <td>simpli</td>\n",
              "      <td>wish</td>\n",
              "      <td>remov</td>\n",
              "      <td>futur</td>\n",
              "      <td>messag</td>\n",
              "      <td>click</td>\n",
              "      <td>kj</td>\n",
              "      <td>h</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4355</th>\n",
              "      <td>think</td>\n",
              "      <td>articl</td>\n",
              "      <td>confus</td>\n",
              "      <td>social</td>\n",
              "      <td>bureaucraci</td>\n",
              "      <td>libertarian</td>\n",
              "      <td>implement</td>\n",
              "      <td>north</td>\n",
              "      <td>america</td>\n",
              "      <td>exactli</td>\n",
              "      <td>shine</td>\n",
              "      <td>pinnacl</td>\n",
              "      <td>econom</td>\n",
              "      <td>effici</td>\n",
              "      <td>tri</td>\n",
              "      <td>start</td>\n",
              "      <td>telephon</td>\n",
              "      <td>compani</td>\n",
              "      <td>us</td>\n",
              "      <td>even</td>\n",
              "      <td>wors</td>\n",
              "      <td>canada</td>\n",
              "      <td>take</td>\n",
              "      <td>year</td>\n",
              "      <td>get</td>\n",
              "      <td>bless</td>\n",
              "      <td>permit</td>\n",
              "      <td>raj</td>\n",
              "      <td>fcc</td>\n",
              "      <td>puc</td>\n",
              "      <td>ptt</td>\n",
              "      <td>decidedli</td>\n",
              "      <td>socialist</td>\n",
              "      <td>lean</td>\n",
              "      <td>canada</td>\n",
              "      <td>industri</td>\n",
              "      <td>canada</td>\n",
              "      <td>crtc</td>\n",
              "      <td>yet</td>\n",
              "      <td>despit</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4845</th>\n",
              "      <td>mean</td>\n",
              "      <td>like</td>\n",
              "      <td>mac</td>\n",
              "      <td>keyboard</td>\n",
              "      <td>microsoft</td>\n",
              "      <td>usb</td>\n",
              "      <td>keyboard</td>\n",
              "      <td>ms</td>\n",
              "      <td>internet</td>\n",
              "      <td>pro</td>\n",
              "      <td>unit</td>\n",
              "      <td>two</td>\n",
              "      <td>port</td>\n",
              "      <td>hub</td>\n",
              "      <td>consid</td>\n",
              "      <td>use</td>\n",
              "      <td>flash</td>\n",
              "      <td>unit</td>\n",
              "      <td>one</td>\n",
              "      <td>storag</td>\n",
              "      <td>key</td>\n",
              "      <td>unfortun</td>\n",
              "      <td>kvm</td>\n",
              "      <td>switch</td>\n",
              "      <td>would</td>\n",
              "      <td>drive</td>\n",
              "      <td>client</td>\n",
              "      <td>program</td>\n",
              "      <td>crazi</td>\n",
              "      <td>switch</td>\n",
              "      <td>machin</td>\n",
              "      <td>kearney</td>\n",
              "      <td>http</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  7661 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0       1        2              3     ...  7657  7658  7659  7660\n",
              "DOC_ID                                           ...                        \n",
              "2890        mon     sep     rick           rick  ...  None  None  None  None\n",
              "5070       adam  beberg    write  interestingli  ...  None  None  None  None\n",
              "1293    thought   order  mortgat           loan  ...  None  None  None  None\n",
              "4355      think  articl   confus         social  ...  None  None  None  None\n",
              "4845       mean    like      mac       keyboard  ...  None  None  None  None\n",
              "\n",
              "[5 rows x 7661 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1aKarzEFhjH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "7a987d4b-3cdb-460b-c0a1-aa9df5ac886a"
      },
      "source": [
        "y_train.head() # Note that our DOC_ID matches between X and y datasets"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Doc_ID\n",
              "2890    0\n",
              "5070    0\n",
              "1293    1\n",
              "4355    0\n",
              "4845    0\n",
              "Name: Category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVIfhpBlFkK4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "195f182b-48e2-48f0-f78b-5f9580df5990"
      },
      "source": [
        "# Creating the Sparse Matrix\n",
        "\n",
        "# Create a particular index given a  DataFrame\n",
        "word_index = pd.Index(vocabulary.Vocab_Words)\n",
        "\n",
        "type(word_index)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.indexes.base.Index"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOiugGO6FsMB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's create our function to process\n",
        "\n",
        "def create_sparse_matrix(df, indexed_words, labels): # Data Frame, Index Words + y values\n",
        "    \n",
        "    \"\"\"\n",
        "    Returns spare matrix as dataframe\n",
        "    \n",
        "    df: A dataframe with words in the columns with a document id (Doc_Id) as an index (X_train or X_test).\n",
        "    indexed_words\n",
        "    \n",
        "    indexed_words: Index of words by word id (Word_Id)\n",
        "    \n",
        "    labels: Category as a series (y_train or y_test).\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    # Control variables\n",
        "    nr_rows = df.shape[0]\n",
        "    nr_columns = df.shape[1]\n",
        "    word_set = set(indexed_words) # create a python set from our indexed_words\n",
        "    dict_list = [] # Creates an empty dictionary\n",
        "    \n",
        "    # Loop through df\n",
        "    for i in range(nr_rows):\n",
        "        for j in range(nr_columns):\n",
        "            \n",
        "            word = df.iat[i , j]\n",
        "            \n",
        "            if word in word_set:\n",
        "                \n",
        "                doc_id = df.index[i] # Get the Doc_Id\n",
        "                word_id = indexed_words.get_loc(word) # Get the Word_Id\n",
        "                category = labels.at[doc_id] # Get the category (Spam / Not Spam)\n",
        "                \n",
        "                # Create the item dictionary and append to our list\n",
        "                item= {'LABEL': category, \n",
        "                       'DOC_ID': doc_id, \n",
        "                       'OCCURRENCE': 1, \n",
        "                       'WORD_ID': word_id}\n",
        "                \n",
        "                dict_list.append(item)\n",
        "            \n",
        "    \n",
        "    return pd.DataFrame(dict_list)"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fz42_IIF7tu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d4576d7b-7c15-48d4-ca44-f1a378737292"
      },
      "source": [
        "# Let's run our function\n",
        "sparse_train_df = create_sparse_matrix(X_train, word_index, y_train)\n",
        "\n",
        "# If we take a peek at our Sparse Data Frame we will find that if we have the same word in the email, it is duplicated. So we need to group by \n",
        "sparse_train_df[-5:]  # last 5 rows"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LABEL</th>\n",
              "      <th>DOC_ID</th>\n",
              "      <th>OCCURRENCE</th>\n",
              "      <th>WORD_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>438615</th>\n",
              "      <td>0</td>\n",
              "      <td>5390</td>\n",
              "      <td>1</td>\n",
              "      <td>181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438616</th>\n",
              "      <td>1</td>\n",
              "      <td>860</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438617</th>\n",
              "      <td>1</td>\n",
              "      <td>860</td>\n",
              "      <td>1</td>\n",
              "      <td>438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438618</th>\n",
              "      <td>1</td>\n",
              "      <td>860</td>\n",
              "      <td>1</td>\n",
              "      <td>297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438619</th>\n",
              "      <td>1</td>\n",
              "      <td>860</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        LABEL  DOC_ID  OCCURRENCE  WORD_ID\n",
              "438615      0    5390           1      181\n",
              "438616      1     860           1       10\n",
              "438617      1     860           1      438\n",
              "438618      1     860           1      297\n",
              "438619      1     860           1        0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAQsTHd6GFWP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "d3cf8ae1-91ef-4661-c2b6-08bca77de55f"
      },
      "source": [
        "# Combining occurencies with the Pandas groupby() method\n",
        "train_grouped = sparse_train_df.groupby(['DOC_ID', 'WORD_ID', 'LABEL']).sum() # Group by that keys and sum up the occurencies\n",
        "\n",
        "train_grouped.head()"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>OCCURRENCE</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DOC_ID</th>\n",
              "      <th>WORD_ID</th>\n",
              "      <th>LABEL</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
              "      <th>2</th>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      OCCURRENCE\n",
              "DOC_ID WORD_ID LABEL            \n",
              "0      2       1               1\n",
              "       5       1               1\n",
              "       7       1               4\n",
              "       8       1               2\n",
              "       12      1               1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPXg_h3kGP--",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "833a6cf2-d3e1-411f-bba6-d44c61baf6a4"
      },
      "source": [
        "# Will make our doc id for every single row and not summarized\n",
        "train_grouped = train_grouped.reset_index()\n",
        "train_grouped.head()"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DOC_ID</th>\n",
              "      <th>WORD_ID</th>\n",
              "      <th>LABEL</th>\n",
              "      <th>OCCURRENCE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   DOC_ID  WORD_ID  LABEL  OCCURRENCE\n",
              "0       0        2      1           1\n",
              "1       0        5      1           1\n",
              "2       0        7      1           4\n",
              "3       0        8      1           2\n",
              "4       0       12      1           1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CXCe9OUGUk4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saving our work (as .txt)\n",
        "np.savetxt(TRAINING_DATA_FILE, train_grouped, fmt='%d') # Relative Path , Data to be saved, and format"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABkRNO5gGX4C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a spare matrix for our test dataframe\n",
        "\n",
        "# Create the sparse matrix\n",
        "sparse_test_df = create_sparse_matrix(X_test, word_index, y_test)\n",
        "\n",
        "# Group our data by 3 columns summing up our Occurencies\n",
        "test_grouped = sparse_test_df.groupby(['DOC_ID', 'WORD_ID', 'LABEL']).sum()\n",
        "\n",
        "# Add the Doc_Id for each row (Reseting the index)\n",
        "test_grouped = train_grouped.reset_index()\n",
        "\n",
        "# Saving our grouped test (as .txt)\n",
        "np.savetxt(TEST_DATA_FILE, test_grouped, fmt='%d') # Relative Path , Data to be saved, and format"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8q8oDOTAGbda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checking our text pre-processing\n",
        "\n",
        "# We started with 5.796 emails, and then splitted in 4.057 and 1.739 for testing. Are the number equal to our .txt?\n",
        "# How many individual emails were included in the testing file?\n",
        "\n",
        "# Check our Document IDs \n",
        "train_doc_ids = set(train_grouped.DOC_ID) # 4.014 vs 4.057 \n",
        "test_doc_ids = set(test_grouped.DOC_ID) # 1.723  vs 1.739\n",
        "\n",
        "# Why some emails were excluded? Which were the emails?\n",
        "\n",
        "# 1st let's compare the sets\n",
        "set(X_test.index.values) - test_doc_ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXNBClN0DaxI",
        "colab_type": "text"
      },
      "source": [
        "## Extra Topic: Word Cloud charts\n",
        "\n",
        "It's not scientific but it's beautiful! and grabs people's attention\n",
        "\n"
      ]
    }
  ]
}